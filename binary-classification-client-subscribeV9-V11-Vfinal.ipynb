{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:57:39.825756Z","iopub.execute_input":"2025-08-13T23:57:39.826110Z","iopub.status.idle":"2025-08-13T23:57:41.033750Z","shell.execute_reply.started":"2025-08-13T23:57:39.826077Z","shell.execute_reply":"2025-08-13T23:57:41.032949Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e8/sample_submission.csv\n/kaggle/input/playground-series-s5e8/train.csv\n/kaggle/input/playground-series-s5e8/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\n# DATA MANIPULATION\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom scipy.stats import pearsonr, spearmanr\nimport math\n\n# MACHINE LEARNING - SCIKIT-LEARN\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedKFold, KFold\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.feature_selection import SelectKBest, chi2, f_classif, RFE, RFECV\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.svm import SVC, SVR\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, roc_auc_score, roc_curve, auc\nfrom sklearn.pipeline import Pipeline\n\n# ADVANCED ML LIBRARIES\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom lightgbm import LGBMClassifier\n\n# VISUALIZATION\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.offline as pyo\n\n# CONFIGURATION FOR PLOTS\nplt.style.use('seaborn-v0_8')\nsns.set_palette(\"husl\")\n%matplotlib inline\n\n# TEXT PROCESSING (NLP)\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom wordcloud import WordCloud\n\n# DEEP LEARNING \ntry:\n    import tensorflow as tf\n    from tensorflow import keras\n    from tensorflow.keras.models import Sequential\n    from tensorflow.keras.layers import Dense, Dropout, LSTM, Conv2D, MaxPooling2D, Flatten\n    from tensorflow.keras.optimizers import Adam\n    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n    print(\"TensorFlow disponible\")\nexcept ImportError:\n    print(\"TensorFlow no disponible en este entorno\")\n\n\n# UTILITIES\nimport os\nimport sys\nimport warnings\nimport itertools\nfrom datetime import datetime, timedelta\nimport time\nfrom collections import Counter\nimport pickle\nimport joblib\n\n# JUPYTER SPECIFIC\nfrom IPython.display import display, HTML\nfrom tqdm.notebook import tqdm\n\n# SUPPRESS WARNINGS\nwarnings.filterwarnings('ignore')\n\n# PANDAS CONFIGURATION\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)\n\n# NUMPY CONFIGURATION\nnp.random.seed(42)\n\n# PLOTLY CONFIGURATION\npyo.init_notebook_mode(connected=True)\n\nprint(\"✅ Todas las librerías importadas correctamente!\")\nprint(f\"📊 Pandas version: {pd.__version__}\")\nprint(f\"🔢 NumPy version: {np.__version__}\")\nprint(f\"🤖 Scikit-learn version: {__import__('sklearn').__version__}\")\nprint(f\"📈 Matplotlib version: {__import__('matplotlib').__version__}\")\nprint(f\"🎨 Seaborn version: {sns.__version__}\")\n\n\ndef quick_info(df):\n    \"\"\"Información rápida del dataset\"\"\"\n    print(f\"📊 Dataset Shape: {df.shape}\")\n    print(f\"🔢 Columnas numéricas: {df.select_dtypes(include=[np.number]).columns.tolist()}\")\n    print(f\"📝 Columnas categóricas: {df.select_dtypes(include=['object']).columns.tolist()}\")\n    print(f\"❌ Valores nulos por columna:\")\n    print(df.isnull().sum()[df.isnull().sum() > 0])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:57:41.035213Z","iopub.execute_input":"2025-08-13T23:57:41.035758Z","iopub.status.idle":"2025-08-13T23:58:06.814536Z","shell.execute_reply.started":"2025-08-13T23:57:41.035735Z","shell.execute_reply":"2025-08-13T23:58:06.813829Z"}},"outputs":[{"name":"stderr","text":"2025-08-13 23:57:52.512747: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755129472.732944      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755129472.797122      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"TensorFlow disponible\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"name":"stdout","text":"✅ Todas las librerías importadas correctamente!\n📊 Pandas version: 2.2.3\n🔢 NumPy version: 1.26.4\n🤖 Scikit-learn version: 1.2.2\n📈 Matplotlib version: 3.7.2\n🎨 Seaborn version: 0.12.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#https://www.kaggle.com/competitions/playground-series-s5e8/leaderboard? concurso\ntrain = pd.read_csv(\"/kaggle/input/playground-series-s5e8/train.csv\")\ntest =  pd.read_csv(\"/kaggle/input/playground-series-s5e8/test.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:06.815338Z","iopub.execute_input":"2025-08-13T23:58:06.815618Z","iopub.status.idle":"2025-08-13T23:58:09.890516Z","shell.execute_reply.started":"2025-08-13T23:58:06.815597Z","shell.execute_reply":"2025-08-13T23:58:09.889655Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"https://www.kaggle.com/competitions/playground-series-s5e8/overview\n\n*luego de cargar los datos , verificar si hay datos faltantes y tratar de hacer un randomforest lo mas rapido posible\npara ver como viene el modelo y el leaderboard , despues profundizare para entender el dataset y ver como hacer\nun feature eng y proceder a futuro\n","metadata":{}},{"cell_type":"code","source":"#age      : Age of the client (numeric)\n#job      : Type of job (categorical: \"admin.\", \"blue-collar\", \"entrepreneur\", etc.)\n#marital  : Marital status (categorical: \"married\", \"single\", \"divorced\")\n#education: Level of education (categorical: \"primary\", \"secondary\", \"tertiary\", \"unknown\")\n#default  : Has credit in default? (categorical: \"yes\", \"no\")\n#balance  : Average yearly balance in euros (numeric)\n#housing  : Has a housing loan? (categorical: \"yes\", \"no\")\n#loan     : Has a personal loan? (categorical: \"yes\", \"no\")\n#contact  : Type of communication contact (categorical: \"unknown\", \"telephone\", \"cellular\")\n#day      : Last contact day of the month (numeric, 1-31)\n#month    : Last contact month of the year (categorical: \"jan\", \"feb\", \"mar\", …, \"dec\")\n#duration : Last contact duration in seconds (numeric)\n#campaign : Number of contacts performed during this campaign (numeric)\n#pdays    : Number of days since the client was last contacted from a previous campaign (numeric; -1 means the client was not previously contacted)\n#previous : Number of contacts performed before this campaign (numeric)\n#poutcome : Outcome of the previous marketing campaign (categorical: \"unknown\", \"other\", \"failure\", \"success\")\n#y        : The target variable, whether the client subscribed to a term deposit (binary: \"yes\", \"no\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:09.892481Z","iopub.execute_input":"2025-08-13T23:58:09.892748Z","iopub.status.idle":"2025-08-13T23:58:09.897019Z","shell.execute_reply.started":"2025-08-13T23:58:09.892727Z","shell.execute_reply":"2025-08-13T23:58:09.896177Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:09.897916Z","iopub.execute_input":"2025-08-13T23:58:09.898230Z","iopub.status.idle":"2025-08-13T23:58:10.001883Z","shell.execute_reply.started":"2025-08-13T23:58:09.898202Z","shell.execute_reply":"2025-08-13T23:58:10.001119Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   id  age          job  marital  education default  balance housing loan  \\\n0   0   42   technician  married  secondary      no        7      no   no   \n1   1   38  blue-collar  married  secondary      no      514      no   no   \n2   2   36  blue-collar  married  secondary      no      602     yes   no   \n3   3   27      student   single  secondary      no       34     yes   no   \n4   4   26   technician  married  secondary      no      889     yes   no   \n\n    contact  day month  duration  campaign  pdays  previous poutcome  y  \n0  cellular   25   aug       117         3     -1         0  unknown  0  \n1   unknown   18   jun       185         1     -1         0  unknown  0  \n2   unknown   14   may       111         2     -1         0  unknown  0  \n3   unknown   28   may        10         2     -1         0  unknown  0  \n4  cellular    3   feb       902         1     -1         0  unknown  1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>42</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>7</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>25</td>\n      <td>aug</td>\n      <td>117</td>\n      <td>3</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>38</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>514</td>\n      <td>no</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>18</td>\n      <td>jun</td>\n      <td>185</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>36</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>602</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>14</td>\n      <td>may</td>\n      <td>111</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>27</td>\n      <td>student</td>\n      <td>single</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>34</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>28</td>\n      <td>may</td>\n      <td>10</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>26</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>889</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>3</td>\n      <td>feb</td>\n      <td>902</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:10.002767Z","iopub.execute_input":"2025-08-13T23:58:10.003046Z","iopub.status.idle":"2025-08-13T23:58:10.015937Z","shell.execute_reply.started":"2025-08-13T23:58:10.002997Z","shell.execute_reply":"2025-08-13T23:58:10.015057Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       id  age            job  marital  education default  balance housing  \\\n0  750000   32    blue-collar  married  secondary      no     1397     yes   \n1  750001   44     management  married   tertiary      no       23     yes   \n2  750002   36  self-employed  married    primary      no       46     yes   \n3  750003   58    blue-collar  married  secondary      no    -1380     yes   \n4  750004   28     technician   single  secondary      no     1950     yes   \n\n  loan   contact  day month  duration  campaign  pdays  previous poutcome  \n0   no   unknown   21   may       224         1     -1         0  unknown  \n1   no  cellular    3   apr       586         2     -1         0  unknown  \n2  yes  cellular   13   may       111         2     -1         0  unknown  \n3  yes   unknown   29   may       125         1     -1         0  unknown  \n4   no  cellular   22   jul       181         1     -1         0  unknown  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>750000</td>\n      <td>32</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>1397</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>unknown</td>\n      <td>21</td>\n      <td>may</td>\n      <td>224</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>750001</td>\n      <td>44</td>\n      <td>management</td>\n      <td>married</td>\n      <td>tertiary</td>\n      <td>no</td>\n      <td>23</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>3</td>\n      <td>apr</td>\n      <td>586</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>750002</td>\n      <td>36</td>\n      <td>self-employed</td>\n      <td>married</td>\n      <td>primary</td>\n      <td>no</td>\n      <td>46</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>13</td>\n      <td>may</td>\n      <td>111</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>750003</td>\n      <td>58</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>-1380</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>unknown</td>\n      <td>29</td>\n      <td>may</td>\n      <td>125</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>750004</td>\n      <td>28</td>\n      <td>technician</td>\n      <td>single</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>1950</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>22</td>\n      <td>jul</td>\n      <td>181</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"quick_info(train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:10.016881Z","iopub.execute_input":"2025-08-13T23:58:10.017152Z","iopub.status.idle":"2025-08-13T23:58:10.747982Z","shell.execute_reply.started":"2025-08-13T23:58:10.017125Z","shell.execute_reply":"2025-08-13T23:58:10.747217Z"}},"outputs":[{"name":"stdout","text":"📊 Dataset Shape: (750000, 18)\n🔢 Columnas numéricas: ['id', 'age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous', 'y']\n📝 Columnas categóricas: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n❌ Valores nulos por columna:\nSeries([], dtype: int64)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"quick_info(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:10.748748Z","iopub.execute_input":"2025-08-13T23:58:10.748959Z","iopub.status.idle":"2025-08-13T23:58:10.994781Z","shell.execute_reply.started":"2025-08-13T23:58:10.748940Z","shell.execute_reply":"2025-08-13T23:58:10.993989Z"}},"outputs":[{"name":"stdout","text":"📊 Dataset Shape: (250000, 17)\n🔢 Columnas numéricas: ['id', 'age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n📝 Columnas categóricas: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n❌ Valores nulos por columna:\nSeries([], dtype: int64)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#train[\"job\"].value_counts()       # +12-1 management/blue-collar/technician/admin./services/retired/self-employed/entrepeneur/\n                                  #       unemployed/housemaid/student/unknown\n#train[\"marital\"].value_counts()   # +3-1  married/single/divorced\n#train[\"education\"].value_counts() # +4-1 secondary/tertiary/primary/unknown\n#train[\"default\"].value_counts()   # binario reemplazo no = 0 (98.3%), yes  = 1 (1.7%)\n#train[\"housing\"].value_counts()   # binario reemplazo no = 0 (45.16%), yes  = 1 (54.83%)\n#train[\"loan\"].value_counts()      # binario reemplazo no = 0 (86.03%), yes  = 1 (13.97%)\n#train[\"contact\"].value_counts()   # one-hot 2 columnas , cellular/unknown/telephone si ambos son 0 entonces es unknown\n#train[\"month\"].value_counts()     # lo primero que pienso es ordinal pero hay mucha dif entre los valores\n#                                  # la tasa de conversion de abajo me empuja a que sea one-hot o target encoding\n#                                  # dado que mas tarde tmb quiero hacer una NN , hago one-hot y despues pruebo con Target\n#month\n#may    228411\n#aug    128859\n#jul    110647\n#jun     93670\n#nov     66062\n#apr     41319\n#feb     37611\n#jan     18937\n#oct      9204\n#sep      7409\n#mar      5802\n#dec      2069\n#train[\"poutcome\"].value_counts() # one-hot 3 columnas unknown/failure/succes/other si todos son 0 entonces es unknown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:10.995888Z","iopub.execute_input":"2025-08-13T23:58:10.996182Z","iopub.status.idle":"2025-08-13T23:58:11.000306Z","shell.execute_reply.started":"2025-08-13T23:58:10.996151Z","shell.execute_reply":"2025-08-13T23:58:10.999448Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Calcular tasa de conversión por mes\nconversion_by_month = train.groupby('month')['y'].agg(['count', 'sum', 'mean'])\nconversion_by_month.columns = ['total_contacts', 'conversions', 'conversion_rate']\nconversion_by_month = conversion_by_month.sort_values('conversion_rate', ascending=False)\n\nprint(conversion_by_month)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:11.002913Z","iopub.execute_input":"2025-08-13T23:58:11.003237Z","iopub.status.idle":"2025-08-13T23:58:11.088814Z","shell.execute_reply.started":"2025-08-13T23:58:11.003216Z","shell.execute_reply":"2025-08-13T23:58:11.087924Z"}},"outputs":[{"name":"stdout","text":"       total_contacts  conversions  conversion_rate\nmonth                                              \nmar              5802         3315         0.571355\nsep              7409         3962         0.534755\ndec              2069         1062         0.513291\noct              9204         4510         0.490004\napr             41319         9737         0.235654\nfeb             37611         7778         0.206801\njan             18937         2351         0.124148\naug            128859        14453         0.112161\nnov             66062         7254         0.109806\njun             93670         9716         0.103726\njul            110647        10052         0.090847\nmay            228411        16298         0.071354\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"#feat Eng\ntrain.describe(include=\"all\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:11.089926Z","iopub.execute_input":"2025-08-13T23:58:11.090220Z","iopub.status.idle":"2025-08-13T23:58:12.134049Z","shell.execute_reply.started":"2025-08-13T23:58:11.090190Z","shell.execute_reply":"2025-08-13T23:58:12.133197Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                   id            age         job  marital  education default  \\\ncount   750000.000000  750000.000000      750000   750000     750000  750000   \nunique            NaN            NaN          12        3          4       2   \ntop               NaN            NaN  management  married  secondary      no   \nfreq              NaN            NaN      175541   480759     401683  737151   \nmean    374999.500000      40.926395         NaN      NaN        NaN     NaN   \nstd     216506.495284      10.098829         NaN      NaN        NaN     NaN   \nmin          0.000000      18.000000         NaN      NaN        NaN     NaN   \n25%     187499.750000      33.000000         NaN      NaN        NaN     NaN   \n50%     374999.500000      39.000000         NaN      NaN        NaN     NaN   \n75%     562499.250000      48.000000         NaN      NaN        NaN     NaN   \nmax     749999.000000      95.000000         NaN      NaN        NaN     NaN   \n\n              balance housing    loan   contact            day   month  \\\ncount   750000.000000  750000  750000    750000  750000.000000  750000   \nunique            NaN       2       2         3            NaN      12   \ntop               NaN     yes      no  cellular            NaN     may   \nfreq              NaN  411288  645023    486655            NaN  228411   \nmean      1204.067397     NaN     NaN       NaN      16.117209     NaN   \nstd       2836.096759     NaN     NaN       NaN       8.250832     NaN   \nmin      -8019.000000     NaN     NaN       NaN       1.000000     NaN   \n25%          0.000000     NaN     NaN       NaN       9.000000     NaN   \n50%        634.000000     NaN     NaN       NaN      17.000000     NaN   \n75%       1390.000000     NaN     NaN       NaN      21.000000     NaN   \nmax      99717.000000     NaN     NaN       NaN      31.000000     NaN   \n\n             duration       campaign          pdays       previous poutcome  \\\ncount   750000.000000  750000.000000  750000.000000  750000.000000   750000   \nunique            NaN            NaN            NaN            NaN        4   \ntop               NaN            NaN            NaN            NaN  unknown   \nfreq              NaN            NaN            NaN            NaN   672450   \nmean       256.229144       2.577008      22.412733       0.298545      NaN   \nstd        272.555662       2.718514      77.319998       1.335926      NaN   \nmin          1.000000       1.000000      -1.000000       0.000000      NaN   \n25%         91.000000       1.000000      -1.000000       0.000000      NaN   \n50%        133.000000       2.000000      -1.000000       0.000000      NaN   \n75%        361.000000       3.000000      -1.000000       0.000000      NaN   \nmax       4918.000000      63.000000     871.000000     200.000000      NaN   \n\n                    y  \ncount   750000.000000  \nunique            NaN  \ntop               NaN  \nfreq              NaN  \nmean         0.120651  \nstd          0.325721  \nmin          0.000000  \n25%          0.000000  \n50%          0.000000  \n75%          0.000000  \nmax          1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000</td>\n      <td>750000</td>\n      <td>750000</td>\n      <td>750000</td>\n      <td>750000.000000</td>\n      <td>750000</td>\n      <td>750000</td>\n      <td>750000</td>\n      <td>750000.000000</td>\n      <td>750000</td>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000</td>\n      <td>750000.000000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>management</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>NaN</td>\n      <td>may</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>unknown</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>175541</td>\n      <td>480759</td>\n      <td>401683</td>\n      <td>737151</td>\n      <td>NaN</td>\n      <td>411288</td>\n      <td>645023</td>\n      <td>486655</td>\n      <td>NaN</td>\n      <td>228411</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>672450</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>374999.500000</td>\n      <td>40.926395</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1204.067397</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.117209</td>\n      <td>NaN</td>\n      <td>256.229144</td>\n      <td>2.577008</td>\n      <td>22.412733</td>\n      <td>0.298545</td>\n      <td>NaN</td>\n      <td>0.120651</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>216506.495284</td>\n      <td>10.098829</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2836.096759</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.250832</td>\n      <td>NaN</td>\n      <td>272.555662</td>\n      <td>2.718514</td>\n      <td>77.319998</td>\n      <td>1.335926</td>\n      <td>NaN</td>\n      <td>0.325721</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>18.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-8019.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>187499.750000</td>\n      <td>33.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.000000</td>\n      <td>NaN</td>\n      <td>91.000000</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>374999.500000</td>\n      <td>39.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>634.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.000000</td>\n      <td>NaN</td>\n      <td>133.000000</td>\n      <td>2.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>562499.250000</td>\n      <td>48.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1390.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.000000</td>\n      <td>NaN</td>\n      <td>361.000000</td>\n      <td>3.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>749999.000000</td>\n      <td>95.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99717.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>31.000000</td>\n      <td>NaN</td>\n      <td>4918.000000</td>\n      <td>63.000000</td>\n      <td>871.000000</td>\n      <td>200.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"#   # Feature Importance XGB\n# 26   poutcome_success    0.295378\n# 14          month_mar    0.095745\n# 7            duration    0.074167\n# 11   contact_cellular    0.067707\n# 4             housing    0.044851\n# 21          month_oct    0.037620\n# 15          month_apr    0.034245\n# 17          month_jun    0.033480\n# 20          month_sep    0.030168\n# 12  contact_telephone    0.024734\n# 5                loan    0.022850\n# 27    job_blue-collar    0.020831\n# 16          month_may    0.019547\n# 13          month_feb    0.017789\n# 18          month_jul    0.014844\n# 22          month_nov    0.013827\n# 23          month_dec    0.013768\n# 19          month_aug    0.012835\n# 9               pdays    0.009650\n# 10           previous    0.009134\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.135214Z","iopub.execute_input":"2025-08-13T23:58:12.135482Z","iopub.status.idle":"2025-08-13T23:58:12.139117Z","shell.execute_reply.started":"2025-08-13T23:58:12.135453Z","shell.execute_reply":"2025-08-13T23:58:12.138313Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"\n\n# # 1. Histograma general de duration\n# plt.figure(figsize=(12, 4))\n\n# plt.subplot(1, 3, 1)\n# plt.hist(train['duration'], bins=100, alpha=0.7, edgecolor='black')\n# plt.title('Duration - Todos los casos')\n# plt.xlabel('Duration')\n# plt.ylabel('Frecuencia')\n\n# # 2. Histograma para y >= 0.5 (casos positivos)\n# plt.subplot(1, 3, 2)\n# duration_positive = train[train['y'] >= 0.5]['duration']\n# plt.hist(duration_positive, bins=100, alpha=0.7, color='green', edgecolor='black')\n# plt.title('Duration - y >= 0.5')\n# plt.xlabel('Duration')\n# plt.ylabel('Frecuencia')\n\n# # 3. Histograma para y < 0.5 (casos negativos)\n# plt.subplot(1, 3, 3)\n# duration_negative = train[train['y'] < 0.5]['duration']\n# plt.hist(duration_negative, bins=range(0,1000,50), alpha=0.7, color='red', edgecolor='black')\n# plt.title('Duration - y < 0.5')\n# plt.xlabel('Duration')\n# plt.ylabel('Frecuencia')\n\n# plt.tight_layout()\n# plt.show()\n\n# # Stats rápidas\n# print(f\"Duration media (y>=0.5): {duration_positive.mean():.1f}\")\n# print(f\"Duration media (y<0.5): {duration_negative.mean():.1f}\")\n# print(f\"Duration mediana (y>=0.5): {duration_positive.median():.1f}\")\n# print(f\"Duration mediana (y<0.5): {duration_negative.median():.1f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.139976Z","iopub.execute_input":"2025-08-13T23:58:12.140283Z","iopub.status.idle":"2025-08-13T23:58:12.159924Z","shell.execute_reply.started":"2025-08-13T23:58:12.140258Z","shell.execute_reply":"2025-08-13T23:58:12.159076Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"\n# # HISTOGRAMAS\n# plt.figure(figsize=(15, 8))\n\n# # 1. Histograma general de balance\n# plt.subplot(2, 3, 1)\n# plt.hist(train['balance'], bins=50, alpha=0.7, edgecolor='black')\n# plt.title('Balance - Todos los casos')\n# plt.xlabel('Balance')\n# plt.ylabel('Frecuencia')\n\n# # 2. Histograma para y >= 0.5 (casos positivos)\n# plt.subplot(2, 3, 2)\n# balance_positive = train[train['y'] >= 0.5]['balance']\n# plt.hist(balance_positive, bins=50, alpha=0.7, color='green', edgecolor='black')\n# plt.title('Balance - y >= 0.5')\n# plt.xlabel('Balance')\n# plt.ylabel('Frecuencia')\n\n# # 3. Histograma para y < 0.5 (casos negativos)\n# plt.subplot(2, 3, 3)\n# balance_negative = train[train['y'] < 0.5]['balance']\n# plt.hist(balance_negative, bins=range(0,20000,1000), alpha=0.7, color='red', edgecolor='black')\n# plt.title('Balance - y < 0.5')\n# plt.xlabel('Balance')\n# plt.ylabel('Frecuencia')\n\n# # BOXPLOTS\n# plt.subplot(2, 3, 4)\n# plt.boxplot(train['balance'])\n# plt.title('Balance - Todos')\n# plt.ylabel('Balance')\n\n# plt.subplot(2, 3, 5)\n# plt.boxplot(balance_positive, patch_artist=True, \n#            boxprops=dict(facecolor='lightgreen'))\n# plt.title('Balance - y >= 0.5')\n# plt.ylabel('Balance')\n\n# plt.subplot(2, 3, 6)\n# plt.boxplot(balance_negative, patch_artist=True,\n#            boxprops=dict(facecolor='lightcoral'))\n# plt.title('Balance - y < 0.5')\n# plt.ylabel('Balance')\n\n# plt.tight_layout()\n# plt.show()\n\n# # ESTADÍSTICAS DESCRIPTIVAS\n# def print_quartiles(data, label):\n#     q25 = np.percentile(data, 25)\n#     q50 = np.percentile(data, 50)  # mediana\n#     q75 = np.percentile(data, 75)\n#     print(f\"\\n{label}:\")\n#     print(f\"  Q1 (25%): {q25:.1f}\")\n#     print(f\"  Q2 (50% - Mediana): {q50:.1f}\")\n#     print(f\"  Q3 (75%): {q75:.1f}\")\n#     print(f\"  Media: {data.mean():.1f}\")\n#     print(f\"  Min: {data.min():.1f}\")\n#     print(f\"  Max: {data.max():.1f}\")\n#     print(f\"  Count: {len(data)}\")\n\n# # Imprimir estadísticas\n# print_quartiles(train['balance'], \"BALANCE - TODOS\")\n# print_quartiles(balance_positive, \"BALANCE - y >= 0.5\")\n# print_quartiles(balance_negative, \"BALANCE - y < 0.5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.160852Z","iopub.execute_input":"2025-08-13T23:58:12.161139Z","iopub.status.idle":"2025-08-13T23:58:12.176461Z","shell.execute_reply.started":"2025-08-13T23:58:12.161114Z","shell.execute_reply":"2025-08-13T23:58:12.175640Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\n# plt.figure(figsize=(15, 8))\n\n# # 1. Distribución general de contact\n# plt.subplot(2, 3, 1)\n# contact_counts = train['contact'].value_counts()\n# plt.bar(contact_counts.index, contact_counts.values, alpha=0.7, edgecolor='black')\n# plt.title('Contact - Todos los casos')\n# plt.xlabel('Contact Type')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 2. Distribución para y >= 0.5\n# plt.subplot(2, 3, 2)\n# contact_positive = train[train['y'] >= 0.5]['contact'].value_counts()\n# plt.bar(contact_positive.index, contact_positive.values, alpha=0.7, color='green', edgecolor='black')\n# plt.title('Contact - y >= 0.5')\n# plt.xlabel('Contact Type')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 3. Distribución para y < 0.5\n# plt.subplot(2, 3, 3)\n# contact_negative = train[train['y'] < 0.5]['contact'].value_counts()\n# plt.bar(contact_negative.index, contact_negative.values, alpha=0.7, color='red', edgecolor='black')\n# plt.title('Contact - y < 0.5')\n# plt.xlabel('Contact Type')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 4. Tasas de conversión por contact type\n# plt.subplot(2, 3, 4)\n# conversion_rates = train.groupby('contact')['y'].agg(['mean', 'count'])\n# plt.bar(conversion_rates.index, conversion_rates['mean'], alpha=0.7, color='orange', edgecolor='black')\n# plt.title('Tasa de Conversión por Contact')\n# plt.xlabel('Contact Type')\n# plt.ylabel('Tasa de Conversión')\n# plt.xticks(rotation=45)\n\n# # 5. Distribución porcentual\n# plt.subplot(2, 3, 5)\n# contact_pct = train['contact'].value_counts(normalize=True) * 100\n# plt.pie(contact_pct.values, labels=contact_pct.index, autopct='%1.1f%%')\n# plt.title('Contact - Distribución %')\n\n# # 6. Comparación lado a lado\n# plt.subplot(2, 3, 6)\n# comparison_data = pd.DataFrame({\n#     'y >= 0.5': train[train['y'] >= 0.5]['contact'].value_counts(),\n#     'y < 0.5': train[train['y'] < 0.5]['contact'].value_counts()\n# }).fillna(0)\n\n# comparison_data.plot(kind='bar', ax=plt.gca(), color=['green', 'red'], alpha=0.7)\n# plt.title('Contact - Comparación')\n# plt.xlabel('Contact Type')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n# plt.legend()\n\n# plt.tight_layout()\n# plt.show()\n\n# # ESTADÍSTICAS\n# print(\"=== ESTADÍSTICAS DE CONTACT ===\")\n# print(\"\\nTodos los casos:\")\n# print(train['contact'].value_counts())\n# print(f\"\\nPorcentajes:\")\n# print((train['contact'].value_counts(normalize=True) * 100).round(1))\n\n# print(f\"\\ny >= 0.5:\")\n# print(train[train['y'] >= 0.5]['contact'].value_counts())\n\n# print(f\"\\ny < 0.5:\")\n# print(train[train['y'] < 0.5]['contact'].value_counts())\n\n# print(f\"\\nTasas de conversión por contact:\")\n# conversion_stats = train.groupby('contact')['y'].agg(['mean', 'count'])\n# conversion_stats['mean'] = (conversion_stats['mean'] * 100).round(2)\n# print(conversion_stats.rename(columns={'mean': 'conversion_rate_%', 'count': 'total_casos'}))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.177348Z","iopub.execute_input":"2025-08-13T23:58:12.177591Z","iopub.status.idle":"2025-08-13T23:58:12.194463Z","shell.execute_reply.started":"2025-08-13T23:58:12.177572Z","shell.execute_reply":"2025-08-13T23:58:12.193673Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# plt.figure(figsize=(15, 8))\n\n# # 1. Distribución general de age\n# plt.subplot(2, 3, 1)\n# plt.hist(train['age'], bins=30, alpha=0.7, edgecolor='black')\n# plt.title('Age - Todos los casos')\n# plt.xlabel('Age')\n# plt.ylabel('Frecuencia')\n\n# # 2. Distribución para y >= 0.5\n# plt.subplot(2, 3, 2)\n# plt.hist(train[train['y'] >= 0.5]['age'], bins=30, alpha=0.7, color='green', edgecolor='black')\n# plt.title('Age - y >= 0.5')\n# plt.xlabel('Age')\n# plt.ylabel('Frecuencia')\n\n# # 3. Distribución para y < 0.5\n# plt.subplot(2, 3, 3)\n# plt.hist(train[train['y'] < 0.5]['age'], bins=30, alpha=0.7, color='red', edgecolor='black')\n# plt.title('Age - y < 0.5')\n# plt.xlabel('Age')\n# plt.ylabel('Frecuencia')\n\n# # 4. Tasas de conversión por age (binned)\n# plt.subplot(2, 3, 4)\n# age_bins = pd.cut(train['age'], bins=20)\n# conversion_rates = train.groupby(age_bins)['y'].agg(['mean', 'count'])\n# bin_centers = [interval.mid for interval in conversion_rates.index]\n# plt.bar(bin_centers, conversion_rates['mean'], alpha=0.7, color='orange', edgecolor='black', width=2)\n# plt.title('Tasa de Conversión por Age')\n# plt.xlabel('Age')\n# plt.ylabel('Tasa de Conversión')\n# plt.xticks(rotation=45)\n\n# # 5. Boxplot comparativo\n# plt.subplot(2, 3, 5)\n# data_to_plot = [train[train['y'] >= 0.5]['age'], train[train['y'] < 0.5]['age']]\n# box_plot = plt.boxplot(data_to_plot, patch_artist=True, labels=['y >= 0.5', 'y < 0.5'])\n# box_plot['boxes'][0].set_facecolor('green')\n# box_plot['boxes'][1].set_facecolor('red')\n# plt.title('Age - Distribución por Clase')\n# plt.ylabel('Age')\n\n# # 6. Comparación de densidades\n# plt.subplot(2, 3, 6)\n# train[train['y'] >= 0.5]['age'].plot(kind='density', alpha=0.7, color='green', label='y >= 0.5')\n# train[train['y'] < 0.5]['age'].plot(kind='density', alpha=0.7, color='red', label='y < 0.5')\n# plt.title('Age - Densidades')\n# plt.xlabel('Age')\n# plt.ylabel('Densidad')\n# plt.legend()\n\n# plt.tight_layout()\n# plt.show()\n\n# # ESTADÍSTICAS\n# print(\"=== ESTADÍSTICAS DE AGE ===\")\n# print(\"\\nTodos los casos:\")\n# print(train['age'].describe())\n\n# print(f\"\\ny >= 0.5:\")\n# print(train[train['y'] >= 0.5]['age'].describe())\n\n# print(f\"\\ny < 0.5:\")\n# print(train[train['y'] < 0.5]['age'].describe())\n\n# print(f\"\\nTasas de conversión por rangos de age:\")\n# age_ranges = pd.cut(train['age'], bins=[0, 25, 35, 45, 55, 65, 100], labels=['<25', '25-34', '35-44', '45-54', '55-64', '65+'])\n# conversion_stats = train.groupby(age_ranges)['y'].agg(['mean', 'count'])\n# conversion_stats['mean'] = (conversion_stats['mean'] * 100).round(2)\n# print(conversion_stats.rename(columns={'mean': 'conversion_rate_%', 'count': 'total_casos'}))\n\n# print(f\"\\nCorrelación con target:\")\n# print(f\"Correlación Pearson: {train['age'].corr(train['y']):.4f}\")\n\n# # Análisis de percentiles para identificar puntos de corte óptimos\n# print(f\"\\nPercentiles de age:\")\n# percentiles = [10, 25, 50, 75, 90, 95, 99]\n# for p in percentiles:\n#     print(f\"P{p}: {train['age'].quantile(p/100):.1f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.195265Z","iopub.execute_input":"2025-08-13T23:58:12.195548Z","iopub.status.idle":"2025-08-13T23:58:12.212946Z","shell.execute_reply.started":"2025-08-13T23:58:12.195517Z","shell.execute_reply":"2025-08-13T23:58:12.212059Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# plt.figure(figsize=(15, 8))\n\n# # 1. Distribución general de job\n# plt.subplot(2, 3, 1)\n# job_counts = train['job'].value_counts()\n# plt.bar(job_counts.index, job_counts.values, alpha=0.7, edgecolor='black')\n# plt.title('Job - Todos los casos')\n# plt.xlabel('Job Type')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 2. Distribución para y >= 0.5\n# plt.subplot(2, 3, 2)\n# job_positive = train[train['y'] >= 0.5]['job'].value_counts()\n# plt.bar(job_positive.index, job_positive.values, alpha=0.7, color='green', edgecolor='black')\n# plt.title('Job - y >= 0.5')\n# plt.xlabel('Job Type')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 3. Distribución para y < 0.5\n# plt.subplot(2, 3, 3)\n# job_negative = train[train['y'] < 0.5]['job'].value_counts()\n# plt.bar(job_negative.index, job_negative.values, alpha=0.7, color='red', edgecolor='black')\n# plt.title('Job - y < 0.5')\n# plt.xlabel('Job Type')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 4. Tasas de conversión por job type\n# plt.subplot(2, 3, 4)\n# conversion_rates = train.groupby('job')['y'].agg(['mean', 'count'])\n# plt.bar(conversion_rates.index, conversion_rates['mean'], alpha=0.7, color='orange', edgecolor='black')\n# plt.title('Tasa de Conversión por Job')\n# plt.xlabel('Job Type')\n# plt.ylabel('Tasa de Conversión')\n# plt.xticks(rotation=45)\n\n# # 5. Distribución porcentual\n# plt.subplot(2, 3, 5)\n# job_pct = train['job'].value_counts(normalize=True) * 100\n# plt.pie(job_pct.values, labels=job_pct.index, autopct='%1.1f%%')\n# plt.title('Job - Distribución %')\n\n# # 6. Comparación lado a lado\n# plt.subplot(2, 3, 6)\n# comparison_data = pd.DataFrame({\n#     'y >= 0.5': train[train['y'] >= 0.5]['job'].value_counts(),\n#     'y < 0.5': train[train['y'] < 0.5]['job'].value_counts()\n# }).fillna(0)\n# comparison_data.plot(kind='bar', ax=plt.gca(), color=['green', 'red'], alpha=0.7)\n# plt.title('Job - Comparación')\n# plt.xlabel('Job Type')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n# plt.legend()\n\n# plt.tight_layout()\n# plt.show()\n\n# # ESTADÍSTICAS\n# print(\"=== ESTADÍSTICAS DE JOB ===\")\n# print(\"\\nTodos los casos:\")\n# print(train['job'].value_counts())\n\n# print(f\"\\nPorcentajes:\")\n# print((train['job'].value_counts(normalize=True) * 100).round(1))\n\n# print(f\"\\ny >= 0.5:\")\n# print(train[train['y'] >= 0.5]['job'].value_counts())\n\n# print(f\"\\ny < 0.5:\")\n# print(train[train['y'] < 0.5]['job'].value_counts())\n\n# print(f\"\\nTasas de conversión por job:\")\n# conversion_stats = train.groupby('job')['y'].agg(['mean', 'count'])\n# conversion_stats['mean'] = (conversion_stats['mean'] * 100).round(2)\n# print(conversion_stats.rename(columns={'mean': 'conversion_rate_%', 'count': 'total_casos'}).sort_values('conversion_rate_%', ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.213916Z","iopub.execute_input":"2025-08-13T23:58:12.214846Z","iopub.status.idle":"2025-08-13T23:58:12.233223Z","shell.execute_reply.started":"2025-08-13T23:58:12.214820Z","shell.execute_reply":"2025-08-13T23:58:12.232306Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# plt.figure(figsize=(15, 8))\n\n# # 1. Distribución general de marital\n# plt.subplot(2, 3, 1)\n# marital_counts = train['marital'].value_counts()\n# plt.bar(marital_counts.index, marital_counts.values, alpha=0.7, edgecolor='black')\n# plt.title('Marital - Todos los casos')\n# plt.xlabel('Marital Status')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 2. Distribución para y >= 0.5\n# plt.subplot(2, 3, 2)\n# marital_positive = train[train['y'] >= 0.5]['marital'].value_counts()\n# plt.bar(marital_positive.index, marital_positive.values, alpha=0.7, color='green', edgecolor='black')\n# plt.title('Marital - y >= 0.5')\n# plt.xlabel('Marital Status')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 3. Distribución para y < 0.5\n# plt.subplot(2, 3, 3)\n# marital_negative = train[train['y'] < 0.5]['marital'].value_counts()\n# plt.bar(marital_negative.index, marital_negative.values, alpha=0.7, color='red', edgecolor='black')\n# plt.title('Marital - y < 0.5')\n# plt.xlabel('Marital Status')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 4. Tasas de conversión por marital status\n# plt.subplot(2, 3, 4)\n# conversion_rates = train.groupby('marital')['y'].agg(['mean', 'count'])\n# plt.bar(conversion_rates.index, conversion_rates['mean'], alpha=0.7, color='orange', edgecolor='black')\n# plt.title('Tasa de Conversión por Marital')\n# plt.xlabel('Marital Status')\n# plt.ylabel('Tasa de Conversión')\n# plt.xticks(rotation=45)\n\n# # 5. Distribución porcentual\n# plt.subplot(2, 3, 5)\n# marital_pct = train['marital'].value_counts(normalize=True) * 100\n# plt.pie(marital_pct.values, labels=marital_pct.index, autopct='%1.1f%%')\n# plt.title('Marital - Distribución %')\n\n# # 6. Comparación lado a lado\n# plt.subplot(2, 3, 6)\n# comparison_data = pd.DataFrame({\n#     'y >= 0.5': train[train['y'] >= 0.5]['marital'].value_counts(),\n#     'y < 0.5': train[train['y'] < 0.5]['marital'].value_counts()\n# }).fillna(0)\n# comparison_data.plot(kind='bar', ax=plt.gca(), color=['green', 'red'], alpha=0.7)\n# plt.title('Marital - Comparación')\n# plt.xlabel('Marital Status')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n# plt.legend()\n\n# plt.tight_layout()\n# plt.show()\n\n# # ESTADÍSTICAS\n# print(\"=== ESTADÍSTICAS DE MARITAL ===\")\n# print(\"\\nTodos los casos:\")\n# print(train['marital'].value_counts())\n\n# print(f\"\\nPorcentajes:\")\n# print((train['marital'].value_counts(normalize=True) * 100).round(1))\n\n# print(f\"\\ny >= 0.5:\")\n# print(train[train['y'] >= 0.5]['marital'].value_counts())\n\n# print(f\"\\ny < 0.5:\")\n# print(train[train['y'] < 0.5]['marital'].value_counts())\n\n# print(f\"\\nTasas de conversión por marital:\")\n# conversion_stats = train.groupby('marital')['y'].agg(['mean', 'count'])\n# conversion_stats['mean'] = (conversion_stats['mean'] * 100).round(2)\n# print(conversion_stats.rename(columns={'mean': 'conversion_rate_%', 'count': 'total_casos'}).sort_values('conversion_rate_%', ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.234414Z","iopub.execute_input":"2025-08-13T23:58:12.234680Z","iopub.status.idle":"2025-08-13T23:58:12.254946Z","shell.execute_reply.started":"2025-08-13T23:58:12.234657Z","shell.execute_reply":"2025-08-13T23:58:12.254072Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# plt.figure(figsize=(15, 8))\n\n# # 1. Distribución general de education\n# plt.subplot(2, 3, 1)\n# education_counts = train['education'].value_counts()\n# plt.bar(education_counts.index, education_counts.values, alpha=0.7, edgecolor='black')\n# plt.title('Education - Todos los casos')\n# plt.xlabel('Education Level')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 2. Distribución para y >= 0.5\n# plt.subplot(2, 3, 2)\n# education_positive = train[train['y'] >= 0.5]['education'].value_counts()\n# plt.bar(education_positive.index, education_positive.values, alpha=0.7, color='green', edgecolor='black')\n# plt.title('Education - y >= 0.5')\n# plt.xlabel('Education Level')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 3. Distribución para y < 0.5\n# plt.subplot(2, 3, 3)\n# education_negative = train[train['y'] < 0.5]['education'].value_counts()\n# plt.bar(education_negative.index, education_negative.values, alpha=0.7, color='red', edgecolor='black')\n# plt.title('Education - y < 0.5')\n# plt.xlabel('Education Level')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 4. Tasas de conversión por education level\n# plt.subplot(2, 3, 4)\n# conversion_rates = train.groupby('education')['y'].agg(['mean', 'count'])\n# plt.bar(conversion_rates.index, conversion_rates['mean'], alpha=0.7, color='orange', edgecolor='black')\n# plt.title('Tasa de Conversión por Education')\n# plt.xlabel('Education Level')\n# plt.ylabel('Tasa de Conversión')\n# plt.xticks(rotation=45)\n\n# # 5. Distribución porcentual\n# plt.subplot(2, 3, 5)\n# education_pct = train['education'].value_counts(normalize=True) * 100\n# plt.pie(education_pct.values, labels=education_pct.index, autopct='%1.1f%%')\n# plt.title('Education - Distribución %')\n\n# # 6. Comparación lado a lado\n# plt.subplot(2, 3, 6)\n# comparison_data = pd.DataFrame({\n#     'y >= 0.5': train[train['y'] >= 0.5]['education'].value_counts(),\n#     'y < 0.5': train[train['y'] < 0.5]['education'].value_counts()\n# }).fillna(0)\n# comparison_data.plot(kind='bar', ax=plt.gca(), color=['green', 'red'], alpha=0.7)\n# plt.title('Education - Comparación')\n# plt.xlabel('Education Level')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n# plt.legend()\n\n# plt.tight_layout()\n# plt.show()\n\n# # ESTADÍSTICAS\n# print(\"=== ESTADÍSTICAS DE EDUCATION ===\")\n# print(\"\\nTodos los casos:\")\n# print(train['education'].value_counts())\n\n# print(f\"\\nPorcentajes:\")\n# print((train['education'].value_counts(normalize=True) * 100).round(1))\n\n# print(f\"\\ny >= 0.5:\")\n# print(train[train['y'] >= 0.5]['education'].value_counts())\n\n# print(f\"\\ny < 0.5:\")\n# print(train[train['y'] < 0.5]['education'].value_counts())\n\n# print(f\"\\nTasas de conversión por education:\")\n# conversion_stats = train.groupby('education')['y'].agg(['mean', 'count'])\n# conversion_stats['mean'] = (conversion_stats['mean'] * 100).round(2)\n# print(conversion_stats.rename(columns={'mean': 'conversion_rate_%', 'count': 'total_casos'}).sort_values('conversion_rate_%', ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.255957Z","iopub.execute_input":"2025-08-13T23:58:12.256300Z","iopub.status.idle":"2025-08-13T23:58:12.274229Z","shell.execute_reply.started":"2025-08-13T23:58:12.256269Z","shell.execute_reply":"2025-08-13T23:58:12.273284Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# plt.figure(figsize=(15, 8))\n\n# # 1. Distribución general de default\n# plt.subplot(2, 3, 1)\n# default_counts = train['default'].value_counts()\n# plt.bar(default_counts.index, default_counts.values, alpha=0.7, edgecolor='black')\n# plt.title('Default - Todos los casos')\n# plt.xlabel('Default Status')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 2. Distribución para y >= 0.5\n# plt.subplot(2, 3, 2)\n# default_positive = train[train['y'] >= 0.5]['default'].value_counts()\n# plt.bar(default_positive.index, default_positive.values, alpha=0.7, color='green', edgecolor='black')\n# plt.title('Default - y >= 0.5')\n# plt.xlabel('Default Status')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 3. Distribución para y < 0.5\n# plt.subplot(2, 3, 3)\n# default_negative = train[train['y'] < 0.5]['default'].value_counts()\n# plt.bar(default_negative.index, default_negative.values, alpha=0.7, color='red', edgecolor='black')\n# plt.title('Default - y < 0.5')\n# plt.xlabel('Default Status')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 4. Tasas de conversión por default status\n# plt.subplot(2, 3, 4)\n# conversion_rates = train.groupby('default')['y'].agg(['mean', 'count'])\n# plt.bar(conversion_rates.index, conversion_rates['mean'], alpha=0.7, color='orange', edgecolor='black')\n# plt.title('Tasa de Conversión por Default')\n# plt.xlabel('Default Status')\n# plt.ylabel('Tasa de Conversión')\n# plt.xticks(rotation=45)\n\n# # 5. Distribución porcentual\n# plt.subplot(2, 3, 5)\n# default_pct = train['default'].value_counts(normalize=True) * 100\n# plt.pie(default_pct.values, labels=default_pct.index, autopct='%1.1f%%')\n# plt.title('Default - Distribución %')\n\n# # 6. Comparación lado a lado\n# plt.subplot(2, 3, 6)\n# comparison_data = pd.DataFrame({\n#     'y >= 0.5': train[train['y'] >= 0.5]['default'].value_counts(),\n#     'y < 0.5': train[train['y'] < 0.5]['default'].value_counts()\n# }).fillna(0)\n# comparison_data.plot(kind='bar', ax=plt.gca(), color=['green', 'red'], alpha=0.7)\n# plt.title('Default - Comparación')\n# plt.xlabel('Default Status')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n# plt.legend()\n\n# plt.tight_layout()\n# plt.show()\n\n# # ESTADÍSTICAS\n# print(\"=== ESTADÍSTICAS DE DEFAULT ===\")\n# print(\"\\nTodos los casos:\")\n# print(train['default'].value_counts())\n\n# print(f\"\\nPorcentajes:\")\n# print((train['default'].value_counts(normalize=True) * 100).round(1))\n\n# print(f\"\\ny >= 0.5:\")\n# print(train[train['y'] >= 0.5]['default'].value_counts())\n\n# print(f\"\\ny < 0.5:\")\n# print(train[train['y'] < 0.5]['default'].value_counts())\n\n# print(f\"\\nTasas de conversión por default:\")\n# conversion_stats = train.groupby('default')['y'].agg(['mean', 'count'])\n# conversion_stats['mean'] = (conversion_stats['mean'] * 100).round(2)\n# print(conversion_stats.rename(columns={'mean': 'conversion_rate_%', 'count': 'total_casos'}).sort_values('conversion_rate_%', ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.275180Z","iopub.execute_input":"2025-08-13T23:58:12.275482Z","iopub.status.idle":"2025-08-13T23:58:12.292814Z","shell.execute_reply.started":"2025-08-13T23:58:12.275455Z","shell.execute_reply":"2025-08-13T23:58:12.291823Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# plt.figure(figsize=(15, 8))\n\n# # 1. Distribución general de default\n# plt.subplot(2, 3, 1)\n# default_counts = train['default'].value_counts()\n# plt.bar(default_counts.index, default_counts.values, alpha=0.7, edgecolor='black')\n# plt.title('Default - Todos los casos')\n# plt.xlabel('Default Status')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 2. Distribución para y >= 0.5\n# plt.subplot(2, 3, 2)\n# default_positive = train[train['y'] >= 0.5]['default'].value_counts()\n# plt.bar(default_positive.index, default_positive.values, alpha=0.7, color='green', edgecolor='black')\n# plt.title('Default - y >= 0.5')\n# plt.xlabel('Default Status')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 3. Distribución para y < 0.5\n# plt.subplot(2, 3, 3)\n# default_negative = train[train['y'] < 0.5]['default'].value_counts()\n# plt.bar(default_negative.index, default_negative.values, alpha=0.7, color='red', edgecolor='black')\n# plt.title('Default - y < 0.5')\n# plt.xlabel('Default Status')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 4. Tasas de conversión por default status\n# plt.subplot(2, 3, 4)\n# conversion_rates = train.groupby('default')['y'].agg(['mean', 'count'])\n# plt.bar(conversion_rates.index, conversion_rates['mean'], alpha=0.7, color='orange', edgecolor='black')\n# plt.title('Tasa de Conversión por Default')\n# plt.xlabel('Default Status')\n# plt.ylabel('Tasa de Conversión')\n# plt.xticks(rotation=45)\n\n# # 5. Distribución porcentual\n# plt.subplot(2, 3, 5)\n# default_pct = train['default'].value_counts(normalize=True) * 100\n# plt.pie(default_pct.values, labels=default_pct.index, autopct='%1.1f%%')\n# plt.title('Default - Distribución %')\n\n# # 6. Comparación lado a lado\n# plt.subplot(2, 3, 6)\n# comparison_data = pd.DataFrame({\n#     'y >= 0.5': train[train['y'] >= 0.5]['default'].value_counts(),\n#     'y < 0.5': train[train['y'] < 0.5]['default'].value_counts()\n# }).fillna(0)\n# comparison_data.plot(kind='bar', ax=plt.gca(), color=['green', 'red'], alpha=0.7)\n# plt.title('Default - Comparación')\n# plt.xlabel('Default Status')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n# plt.legend()\n\n# plt.tight_layout()\n# plt.show()\n\n# # ESTADÍSTICAS\n# print(\"=== ESTADÍSTICAS DE HOUSING ===\")\n# print(\"\\nTodos los casos:\")\n# print(train['housing'].value_counts())\n\n# print(f\"\\nPorcentajes:\")\n# print((train['housing'].value_counts(normalize=True) * 100).round(1))\n\n# print(f\"\\ny >= 0.5:\")\n# print(train[train['y'] >= 0.5]['housing'].value_counts())\n\n# print(f\"\\ny < 0.5:\")\n# print(train[train['y'] < 0.5]['housing'].value_counts())\n\n# print(f\"\\nTasas de conversión por housing:\")\n# conversion_stats = train.groupby('housing')['y'].agg(['mean', 'count'])\n# conversion_stats['mean'] = (conversion_stats['mean'] * 100).round(2)\n# print(conversion_stats.rename(columns={'mean': 'conversion_rate_%', 'count': 'total_casos'}).sort_values('conversion_rate_%', ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.294112Z","iopub.execute_input":"2025-08-13T23:58:12.294413Z","iopub.status.idle":"2025-08-13T23:58:12.310386Z","shell.execute_reply.started":"2025-08-13T23:58:12.294391Z","shell.execute_reply":"2025-08-13T23:58:12.309700Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# plt.figure(figsize=(15, 8))\n\n# # 1. Distribución general de loan\n# plt.subplot(2, 3, 1)\n# loan_counts = train['loan'].value_counts()\n# plt.bar(loan_counts.index, loan_counts.values, alpha=0.7, edgecolor='black')\n# plt.title('Loan - Todos los casos')\n# plt.xlabel('Personal Loan')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 2. Distribución para y >= 0.5\n# plt.subplot(2, 3, 2)\n# loan_positive = train[train['y'] >= 0.5]['loan'].value_counts()\n# plt.bar(loan_positive.index, loan_positive.values, alpha=0.7, color='green', edgecolor='black')\n# plt.title('Loan - y >= 0.5')\n# plt.xlabel('Personal Loan')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 3. Distribución para y < 0.5\n# plt.subplot(2, 3, 3)\n# loan_negative = train[train['y'] < 0.5]['loan'].value_counts()\n# plt.bar(loan_negative.index, loan_negative.values, alpha=0.7, color='red', edgecolor='black')\n# plt.title('Loan - y < 0.5')\n# plt.xlabel('Personal Loan')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 4. Tasas de conversión por personal loan\n# plt.subplot(2, 3, 4)\n# conversion_rates = train.groupby('loan')['y'].agg(['mean', 'count'])\n# plt.bar(conversion_rates.index, conversion_rates['mean'], alpha=0.7, color='orange', edgecolor='black')\n# plt.title('Tasa de Conversión por Loan')\n# plt.xlabel('Personal Loan')\n# plt.ylabel('Tasa de Conversión')\n# plt.xticks(rotation=45)\n\n# # 5. Distribución porcentual\n# plt.subplot(2, 3, 5)\n# loan_pct = train['loan'].value_counts(normalize=True) * 100\n# plt.pie(loan_pct.values, labels=loan_pct.index, autopct='%1.1f%%')\n# plt.title('Loan - Distribución %')\n\n# # 6. Comparación lado a lado\n# plt.subplot(2, 3, 6)\n# comparison_data = pd.DataFrame({\n#     'y >= 0.5': train[train['y'] >= 0.5]['loan'].value_counts(),\n#     'y < 0.5': train[train['y'] < 0.5]['loan'].value_counts()\n# }).fillna(0)\n# comparison_data.plot(kind='bar', ax=plt.gca(), color=['green', 'red'], alpha=0.7)\n# plt.title('Loan - Comparación')\n# plt.xlabel('Personal Loan')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n# plt.legend()\n\n# plt.tight_layout()\n# plt.show()\n\n# # ESTADÍSTICAS\n# print(\"=== ESTADÍSTICAS DE LOAN ===\")\n# print(\"\\nTodos los casos:\")\n# print(train['loan'].value_counts())\n\n# print(f\"\\nPorcentajes:\")\n# print((train['loan'].value_counts(normalize=True) * 100).round(1))\n\n# print(f\"\\ny >= 0.5:\")\n# print(train[train['y'] >= 0.5]['loan'].value_counts())\n\n# print(f\"\\ny < 0.5:\")\n# print(train[train['y'] < 0.5]['loan'].value_counts())\n\n# print(f\"\\nTasas de conversión por loan:\")\n# conversion_stats = train.groupby('loan')['y'].agg(['mean', 'count'])\n# conversion_stats['mean'] = (conversion_stats['mean'] * 100).round(2)\n# print(conversion_stats.rename(columns={'mean': 'conversion_rate_%', 'count': 'total_casos'}).sort_values('conversion_rate_%', ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.311340Z","iopub.execute_input":"2025-08-13T23:58:12.311594Z","iopub.status.idle":"2025-08-13T23:58:12.330097Z","shell.execute_reply.started":"2025-08-13T23:58:12.311569Z","shell.execute_reply":"2025-08-13T23:58:12.329151Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# plt.figure(figsize=(15, 8))\n\n# # Crear mapeo de números a días de la semana\n# day_mapping = {1: 'Lunes', 2: 'Martes', 3: 'Miércoles', 4: 'Jueves', 5: 'Viernes', 6: 'Sábado', 7: 'Domingo'}\n# train['day_name'] = train['day'].map(day_mapping)\n\n# # 1. Distribución general de day\n# plt.subplot(2, 3, 1)\n# day_counts = train['day_name'].value_counts()\n# # Ordenar por día de la semana\n# day_order = ['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo']\n# day_counts = day_counts.reindex([day for day in day_order if day in day_counts.index])\n# plt.bar(day_counts.index, day_counts.values, alpha=0.7, edgecolor='black')\n# plt.title('Day - Todos los casos')\n# plt.xlabel('Día de la Semana')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 2. Distribución para y >= 0.5\n# plt.subplot(2, 3, 2)\n# day_positive = train[train['y'] >= 0.5]['day_name'].value_counts()\n# day_positive = day_positive.reindex([day for day in day_order if day in day_positive.index])\n# plt.bar(day_positive.index, day_positive.values, alpha=0.7, color='green', edgecolor='black')\n# plt.title('Day - y >= 0.5')\n# plt.xlabel('Día de la Semana')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 3. Distribución para y < 0.5\n# plt.subplot(2, 3, 3)\n# day_negative = train[train['y'] < 0.5]['day_name'].value_counts()\n# day_negative = day_negative.reindex([day for day in day_order if day in day_negative.index])\n# plt.bar(day_negative.index, day_negative.values, alpha=0.7, color='red', edgecolor='black')\n# plt.title('Day - y < 0.5')\n# plt.xlabel('Día de la Semana')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n\n# # 4. Tasas de conversión por día de la semana\n# plt.subplot(2, 3, 4)\n# conversion_rates = train.groupby('day_name')['y'].agg(['mean', 'count'])\n# conversion_rates = conversion_rates.reindex([day for day in day_order if day in conversion_rates.index])\n# plt.bar(conversion_rates.index, conversion_rates['mean'], alpha=0.7, color='orange', edgecolor='black')\n# plt.title('Tasa de Conversión por Day')\n# plt.xlabel('Día de la Semana')\n# plt.ylabel('Tasa de Conversión')\n# plt.xticks(rotation=45)\n\n# # 5. Distribución porcentual\n# plt.subplot(2, 3, 5)\n# day_pct = train['day_name'].value_counts(normalize=True) * 100\n# day_pct = day_pct.reindex([day for day in day_order if day in day_pct.index])\n# plt.pie(day_pct.values, labels=day_pct.index, autopct='%1.1f%%')\n# plt.title('Day - Distribución %')\n\n# # 6. Comparación lado a lado\n# plt.subplot(2, 3, 6)\n# comparison_data = pd.DataFrame({\n#     'y >= 0.5': train[train['y'] >= 0.5]['day_name'].value_counts(),\n#     'y < 0.5': train[train['y'] < 0.5]['day_name'].value_counts()\n# }).fillna(0)\n# comparison_data = comparison_data.reindex([day for day in day_order if day in comparison_data.index])\n# comparison_data.plot(kind='bar', ax=plt.gca(), color=['green', 'red'], alpha=0.7)\n# plt.title('Day - Comparación')\n# plt.xlabel('Día de la Semana')\n# plt.ylabel('Frecuencia')\n# plt.xticks(rotation=45)\n# plt.legend()\n\n# plt.tight_layout()\n# plt.show()\n\n# # ESTADÍSTICAS\n# print(\"=== ESTADÍSTICAS DE DAY ===\")\n# print(\"\\nTodos los casos:\")\n# day_counts_stats = train['day_name'].value_counts()\n# day_counts_stats = day_counts_stats.reindex([day for day in day_order if day in day_counts_stats.index])\n# print(day_counts_stats)\n\n# print(f\"\\nPorcentajes:\")\n# day_pct_stats = (train['day_name'].value_counts(normalize=True) * 100).round(1)\n# day_pct_stats = day_pct_stats.reindex([day for day in day_order if day in day_pct_stats.index])\n# print(day_pct_stats)\n\n# print(f\"\\ny >= 0.5:\")\n# day_pos_stats = train[train['y'] >= 0.5]['day_name'].value_counts()\n# day_pos_stats = day_pos_stats.reindex([day for day in day_order if day in day_pos_stats.index])\n# print(day_pos_stats)\n\n# print(f\"\\ny < 0.5:\")\n# day_neg_stats = train[train['y'] < 0.5]['day_name'].value_counts()\n# day_neg_stats = day_neg_stats.reindex([day for day in day_order if day in day_neg_stats.index])\n# print(day_neg_stats)\n\n# print(f\"\\nTasas de conversión por día:\")\n# conversion_stats = train.groupby('day_name')['y'].agg(['mean', 'count'])\n# conversion_stats['mean'] = (conversion_stats['mean'] * 100).round(2)\n# conversion_stats = conversion_stats.reindex([day for day in day_order if day in conversion_stats.index])\n# print(conversion_stats.rename(columns={'mean': 'conversion_rate_%', 'total_casos': 'total_casos'}).sort_values('conversion_rate_%', ascending=False))\n\n# print(f\"\\nMapeo utilizado:\")\n# print(\"1=Lunes, 2=Martes, 3=Miércoles, 4=Jueves, 5=Viernes, 6=Sábado, 7=Domingo\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.331058Z","iopub.execute_input":"2025-08-13T23:58:12.331528Z","iopub.status.idle":"2025-08-13T23:58:12.350464Z","shell.execute_reply.started":"2025-08-13T23:58:12.331490Z","shell.execute_reply":"2025-08-13T23:58:12.349755Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# plt.figure(figsize=(15, 8))\n\n# # 1. Distribución general de pdays\n# plt.subplot(2, 3, 1)\n# plt.hist(train['pdays'], bins=50, alpha=0.7, edgecolor='black')\n# plt.title('Pdays - Todos los casos')\n# plt.xlabel('Días desde último contacto')\n# plt.ylabel('Frecuencia')\n\n# # 2. Distribución para y >= 0.5\n# plt.subplot(2, 3, 2)\n# plt.hist(train[train['y'] >= 0.5]['pdays'], bins=50, alpha=0.7, color='green', edgecolor='black')\n# plt.title('Pdays - y >= 0.5')\n# plt.xlabel('Días desde último contacto')\n# plt.ylabel('Frecuencia')\n\n# # 3. Distribución para y < 0.5\n# plt.subplot(2, 3, 3)\n# plt.hist(train[train['y'] < 0.5]['pdays'], bins=50, alpha=0.7, color='red', edgecolor='black')\n# plt.title('Pdays - y < 0.5')\n# plt.xlabel('Días desde último contacto')\n# plt.ylabel('Frecuencia')\n\n# # 4. Tasas de conversión por pdays (binned)\n# plt.subplot(2, 3, 4)\n# # Crear bins especiales para pdays considerando el valor -1 (nunca contactado)\n# pdays_bins = [-2, -0.5, 50, 100, 200, 300, 999]\n# pdays_labels = ['Never contacted', '0-50', '51-100', '101-200', '201-300', '300+']\n# train['pdays_binned'] = pd.cut(train['pdays'], bins=pdays_bins, labels=pdays_labels)\n# conversion_rates = train.groupby('pdays_binned')['y'].agg(['mean', 'count'])\n# plt.bar(conversion_rates.index, conversion_rates['mean'], alpha=0.7, color='orange', edgecolor='black')\n# plt.title('Tasa de Conversión por Pdays')\n# plt.xlabel('Días desde último contacto')\n# plt.ylabel('Tasa de Conversión')\n# plt.xticks(rotation=45)\n\n# # 5. Boxplot comparativo\n# plt.subplot(2, 3, 5)\n# # Para el boxplot, filtrar -1 para mejor visualización\n# data_to_plot = [\n#     train[(train['y'] >= 0.5) & (train['pdays'] != -1)]['pdays'], \n#     train[(train['y'] < 0.5) & (train['pdays'] != -1)]['pdays']\n# ]\n# box_plot = plt.boxplot(data_to_plot, patch_artist=True, labels=['y >= 0.5', 'y < 0.5'])\n# box_plot['boxes'][0].set_facecolor('green')\n# box_plot['boxes'][1].set_facecolor('red')\n# plt.title('Pdays - Distribución por Clase\\n(sin -1)')\n# plt.ylabel('Días')\n\n# # 6. Comparación de densidades (sin -1)\n# plt.subplot(2, 3, 6)\n# train[(train['y'] >= 0.5) & (train['pdays'] != -1)]['pdays'].plot(kind='density', alpha=0.7, color='green', label='y >= 0.5')\n# train[(train['y'] < 0.5) & (train['pdays'] != -1)]['pdays'].plot(kind='density', alpha=0.7, color='red', label='y < 0.5')\n# plt.title('Pdays - Densidades\\n(sin -1)')\n# plt.xlabel('Días')\n# plt.ylabel('Densidad')\n# plt.legend()\n\n# plt.tight_layout()\n# plt.show()\n\n# # ESTADÍSTICAS\n# print(\"=== ESTADÍSTICAS DE PDAYS ===\")\n# print(\"\\nTodos los casos:\")\n# print(train['pdays'].describe())\n\n# print(f\"\\nConteo de valor especial -1 (nunca contactado):\")\n# print(f\"Casos con pdays = -1: {(train['pdays'] == -1).sum()}\")\n# print(f\"Porcentaje con pdays = -1: {((train['pdays'] == -1).sum() / len(train) * 100):.1f}%\")\n\n# print(f\"\\nEstadísticas sin -1:\")\n# pdays_without_minus1 = train[train['pdays'] != -1]['pdays']\n# print(pdays_without_minus1.describe())\n\n# print(f\"\\ny >= 0.5:\")\n# print(train[train['y'] >= 0.5]['pdays'].describe())\n\n# print(f\"\\ny < 0.5:\")\n# print(train[train['y'] < 0.5]['pdays'].describe())\n\n# print(f\"\\nTasas de conversión por rangos de pdays:\")\n# conversion_stats = train.groupby('pdays_binned')['y'].agg(['mean', 'count'])\n# conversion_stats['mean'] = (conversion_stats['mean'] * 100).round(2)\n# print(conversion_stats.rename(columns={'mean': 'conversion_rate_%', 'count': 'total_casos'}).sort_values('conversion_rate_%', ascending=False))\n\n# print(f\"\\nCorrelación con target (incluyendo -1):\")\n# print(f\"Correlación Pearson: {train['pdays'].corr(train['y']):.4f}\")\n\n# print(f\"\\nCorrelación con target (sin -1):\")\n# correlation_without_minus1 = train[train['pdays'] != -1]['pdays'].corr(train[train['pdays'] != -1]['y'])\n# print(f\"Correlación Pearson: {correlation_without_minus1:.4f}\")\n\n# # Análisis del valor -1\n# print(f\"\\nAnálisis del valor -1 (nunca contactado):\")\n# never_contacted = train[train['pdays'] == -1]\n# previously_contacted = train[train['pdays'] != -1]\n# print(f\"Tasa conversión nunca contactados: {(never_contacted['y'].mean() * 100):.2f}%\")\n# print(f\"Tasa conversión previamente contactados: {(previously_contacted['y'].mean() * 100):.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.351450Z","iopub.execute_input":"2025-08-13T23:58:12.351688Z","iopub.status.idle":"2025-08-13T23:58:12.370501Z","shell.execute_reply.started":"2025-08-13T23:58:12.351669Z","shell.execute_reply":"2025-08-13T23:58:12.369715Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# plt.figure(figsize=(15, 8))\n\n# # 1. Distribución general de previous\n# plt.subplot(2, 3, 1)\n# plt.hist(train['previous'], bins=20, alpha=0.7, edgecolor='black')\n# plt.title('Previous - Todos los casos')\n# plt.xlabel('Número de contactos previos')\n# plt.ylabel('Frecuencia')\n\n# # 2. Distribución para y >= 0.5\n# plt.subplot(2, 3, 2)\n# plt.hist(train[train['y'] >= 0.5]['previous'], bins=20, alpha=0.7, color='green', edgecolor='black')\n# plt.title('Previous - y >= 0.5')\n# plt.xlabel('Número de contactos previos')\n# plt.ylabel('Frecuencia')\n\n# # 3. Distribución para y < 0.5\n# plt.subplot(2, 3, 3)\n# plt.hist(train[train['y'] < 0.5]['previous'], bins=20, alpha=0.7, color='red', edgecolor='black')\n# plt.title('Previous - y < 0.5')\n# plt.xlabel('Número de contactos previos')\n# plt.ylabel('Frecuencia')\n\n# # 4. Tasas de conversión por número de contactos previos\n# plt.subplot(2, 3, 4)\n# # Crear categorías para better visualization\n# train['previous_cat'] = train['previous'].apply(lambda x: '0' if x == 0 else '1' if x == 1 else '2' if x == 2 else '3+' if x >= 3 else str(x))\n# conversion_rates = train.groupby('previous_cat')['y'].agg(['mean', 'count'])\n# # Ordenar las categorías\n# category_order = ['0', '1', '2', '3+']\n# conversion_rates = conversion_rates.reindex([cat for cat in category_order if cat in conversion_rates.index])\n# plt.bar(conversion_rates.index, conversion_rates['mean'], alpha=0.7, color='orange', edgecolor='black')\n# plt.title('Tasa de Conversión por Previous')\n# plt.xlabel('Contactos previos')\n# plt.ylabel('Tasa de Conversión')\n\n# # 5. Distribución porcentual de contactos previos\n# plt.subplot(2, 3, 5)\n# previous_counts = train['previous'].value_counts()\n# # Mostrar solo los más frecuentes para mejor visualización\n# top_previous = previous_counts.head(8)\n# plt.pie(top_previous.values, labels=top_previous.index, autopct='%1.1f%%')\n# plt.title('Previous - Top valores %')\n\n# # 6. Boxplot comparativo\n# plt.subplot(2, 3, 6)\n# data_to_plot = [train[train['y'] >= 0.5]['previous'], train[train['y'] < 0.5]['previous']]\n# box_plot = plt.boxplot(data_to_plot, patch_artist=True, labels=['y >= 0.5', 'y < 0.5'])\n# box_plot['boxes'][0].set_facecolor('green')\n# box_plot['boxes'][1].set_facecolor('red')\n# plt.title('Previous - Distribución por Clase')\n# plt.ylabel('Contactos previos')\n\n# plt.tight_layout()\n# plt.show()\n\n# # ESTADÍSTICAS\n# print(\"=== ESTADÍSTICAS DE PREVIOUS ===\")\n# print(\"\\nTodos los casos:\")\n# print(train['previous'].describe())\n\n# print(f\"\\nDistribución de valores:\")\n# print(train['previous'].value_counts().sort_index())\n\n# print(f\"\\nPorcentajes de los valores más frecuentes:\")\n# previous_pct = (train['previous'].value_counts().head(10) / len(train) * 100).round(1)\n# print(previous_pct)\n\n# print(f\"\\ny >= 0.5:\")\n# print(train[train['y'] >= 0.5]['previous'].describe())\n\n# print(f\"\\ny < 0.5:\")\n# print(train[train['y'] < 0.5]['previous'].describe())\n\n# print(f\"\\nTasas de conversión por categorías de previous:\")\n# conversion_stats = train.groupby('previous_cat')['y'].agg(['mean', 'count'])\n# conversion_stats['mean'] = (conversion_stats['mean'] * 100).round(2)\n# conversion_stats = conversion_stats.reindex([cat for cat in category_order if cat in conversion_stats.index])\n# print(conversion_stats.rename(columns={'mean': 'conversion_rate_%', 'count': 'total_casos'}))\n\n# print(f\"\\nTasas de conversión por valores exactos (top 10):\")\n# conversion_by_value = train.groupby('previous')['y'].agg(['mean', 'count'])\n# conversion_by_value['mean'] = (conversion_by_value['mean'] * 100).round(2)\n# conversion_by_value = conversion_by_value.sort_values('count', ascending=False).head(10)\n# print(conversion_by_value.rename(columns={'mean': 'conversion_rate_%', 'count': 'total_casos'}))\n\n# print(f\"\\nCorrelación con target:\")\n# print(f\"Correlación Pearson: {train['previous'].corr(train['y']):.4f}\")\n\n# print(f\"\\nAnálisis de casos sin contactos previos (previous = 0):\")\n# never_contacted = train[train['previous'] == 0]\n# previously_contacted = train[train['previous'] > 0]\n# print(f\"Casos sin contactos previos: {len(never_contacted)} ({(len(never_contacted)/len(train)*100):.1f}%)\")\n# print(f\"Casos con contactos previos: {len(previously_contacted)} ({(len(previously_contacted)/len(train)*100):.1f}%)\")\n# print(f\"Tasa conversión sin contactos previos: {(never_contacted['y'].mean() * 100):.2f}%\")\n# print(f\"Tasa conversión con contactos previos: {(previously_contacted['y'].mean() * 100):.2f}%\")\n\n# # Percentiles para identificar outliers\n# print(f\"\\nPercentiles de previous:\")\n# percentiles = [50, 75, 90, 95, 99, 100]\n# for p in percentiles:\n#     print(f\"P{p}: {train['previous'].quantile(p/100):.0f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.371365Z","iopub.execute_input":"2025-08-13T23:58:12.371616Z","iopub.status.idle":"2025-08-13T23:58:12.390575Z","shell.execute_reply.started":"2025-08-13T23:58:12.371592Z","shell.execute_reply":"2025-08-13T23:58:12.389703Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.describe(include=\"all\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:12.391488Z","iopub.execute_input":"2025-08-13T23:58:12.391758Z","iopub.status.idle":"2025-08-13T23:58:13.436723Z","shell.execute_reply.started":"2025-08-13T23:58:12.391732Z","shell.execute_reply":"2025-08-13T23:58:13.435886Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                   id            age         job  marital  education default  \\\ncount   750000.000000  750000.000000      750000   750000     750000  750000   \nunique            NaN            NaN          12        3          4       2   \ntop               NaN            NaN  management  married  secondary      no   \nfreq              NaN            NaN      175541   480759     401683  737151   \nmean    374999.500000      40.926395         NaN      NaN        NaN     NaN   \nstd     216506.495284      10.098829         NaN      NaN        NaN     NaN   \nmin          0.000000      18.000000         NaN      NaN        NaN     NaN   \n25%     187499.750000      33.000000         NaN      NaN        NaN     NaN   \n50%     374999.500000      39.000000         NaN      NaN        NaN     NaN   \n75%     562499.250000      48.000000         NaN      NaN        NaN     NaN   \nmax     749999.000000      95.000000         NaN      NaN        NaN     NaN   \n\n              balance housing    loan   contact            day   month  \\\ncount   750000.000000  750000  750000    750000  750000.000000  750000   \nunique            NaN       2       2         3            NaN      12   \ntop               NaN     yes      no  cellular            NaN     may   \nfreq              NaN  411288  645023    486655            NaN  228411   \nmean      1204.067397     NaN     NaN       NaN      16.117209     NaN   \nstd       2836.096759     NaN     NaN       NaN       8.250832     NaN   \nmin      -8019.000000     NaN     NaN       NaN       1.000000     NaN   \n25%          0.000000     NaN     NaN       NaN       9.000000     NaN   \n50%        634.000000     NaN     NaN       NaN      17.000000     NaN   \n75%       1390.000000     NaN     NaN       NaN      21.000000     NaN   \nmax      99717.000000     NaN     NaN       NaN      31.000000     NaN   \n\n             duration       campaign          pdays       previous poutcome  \\\ncount   750000.000000  750000.000000  750000.000000  750000.000000   750000   \nunique            NaN            NaN            NaN            NaN        4   \ntop               NaN            NaN            NaN            NaN  unknown   \nfreq              NaN            NaN            NaN            NaN   672450   \nmean       256.229144       2.577008      22.412733       0.298545      NaN   \nstd        272.555662       2.718514      77.319998       1.335926      NaN   \nmin          1.000000       1.000000      -1.000000       0.000000      NaN   \n25%         91.000000       1.000000      -1.000000       0.000000      NaN   \n50%        133.000000       2.000000      -1.000000       0.000000      NaN   \n75%        361.000000       3.000000      -1.000000       0.000000      NaN   \nmax       4918.000000      63.000000     871.000000     200.000000      NaN   \n\n                    y  \ncount   750000.000000  \nunique            NaN  \ntop               NaN  \nfreq              NaN  \nmean         0.120651  \nstd          0.325721  \nmin          0.000000  \n25%          0.000000  \n50%          0.000000  \n75%          0.000000  \nmax          1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000</td>\n      <td>750000</td>\n      <td>750000</td>\n      <td>750000</td>\n      <td>750000.000000</td>\n      <td>750000</td>\n      <td>750000</td>\n      <td>750000</td>\n      <td>750000.000000</td>\n      <td>750000</td>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000.000000</td>\n      <td>750000</td>\n      <td>750000.000000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>management</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>NaN</td>\n      <td>may</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>unknown</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>175541</td>\n      <td>480759</td>\n      <td>401683</td>\n      <td>737151</td>\n      <td>NaN</td>\n      <td>411288</td>\n      <td>645023</td>\n      <td>486655</td>\n      <td>NaN</td>\n      <td>228411</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>672450</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>374999.500000</td>\n      <td>40.926395</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1204.067397</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.117209</td>\n      <td>NaN</td>\n      <td>256.229144</td>\n      <td>2.577008</td>\n      <td>22.412733</td>\n      <td>0.298545</td>\n      <td>NaN</td>\n      <td>0.120651</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>216506.495284</td>\n      <td>10.098829</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2836.096759</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.250832</td>\n      <td>NaN</td>\n      <td>272.555662</td>\n      <td>2.718514</td>\n      <td>77.319998</td>\n      <td>1.335926</td>\n      <td>NaN</td>\n      <td>0.325721</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>18.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-8019.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>187499.750000</td>\n      <td>33.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.000000</td>\n      <td>NaN</td>\n      <td>91.000000</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>374999.500000</td>\n      <td>39.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>634.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.000000</td>\n      <td>NaN</td>\n      <td>133.000000</td>\n      <td>2.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>562499.250000</td>\n      <td>48.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1390.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.000000</td>\n      <td>NaN</td>\n      <td>361.000000</td>\n      <td>3.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>749999.000000</td>\n      <td>95.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99717.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>31.000000</td>\n      <td>NaN</td>\n      <td>4918.000000</td>\n      <td>63.000000</td>\n      <td>871.000000</td>\n      <td>200.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# agregar\n# columna month_succes_rate valores entre 0 y 1\n#       total_contacts  conversions  conversion_rate\n#month                                              \n#mar              5802         3315         0.571355\n#sep              7409         3962         0.534755\n#dec              2069         1062         0.513291\n#oct              9204         4510         0.490004\n#apr             41319         9737         0.235654\n#feb             37611         7778         0.206801\n#jan             18937         2351         0.124148\n#aug            128859        14453         0.112161\n#nov             66062         7254         0.109806\n#jun             93670         9716         0.103726\n#jul            110647        10052         0.090847\n#may            228411        16298         0.071354\n# balance inferior a 565 mas duration inferior a 203.8(media de los que no) y contact unknown ,crear columna binaria que se llame Non-interested\n#Tasas de conversión por rangos de age: crear columna S-R-U , personas menos de 25 o mayores de 65 , y que job sea student or retired or unemployed\n# columna binaria con 1 y 0 \n#       conversion_rate_%  total_casos\n#age                                  \n#<25                26.92        16860\n#25-34              13.04       260150\n#35-44               9.64       233150\n#45-54               9.14       164337\n#55-64              15.26        67370\n#65+                52.19         8133\n#Tasas de conversión por job:\n#               conversion_rate_%  total_casos\n#job                                          \n#student                    34.08        11767\n#retired                    24.62        35185\n#unemployed                 17.98        17634\n#management                 15.04       175541\n#self-employed              12.94        19020\n#unknown                    12.07         2917\n#technician                 11.83       138107\n#admin.                     11.65        81492\n#housemaid                   8.47        15912\n#services                    8.27        64209\n#entrepreneur                8.14        17718\n#blue-collar                 6.74       170498\n#Tasas de conversión por marital:\n#          conversion_rate_%  total_casos\n#marital                                 \n#single                17.05       194834\n#divorced              11.16        74407\n#married               10.19       480759\n#Tasas de conversión por education:\n#           conversion_rate_%  total_casos\n#education                                \n#tertiary               16.26       227508\n#unknown                13.34        21299\n#secondary              10.55       401683\n#primary                 8.31        99510\n# crear columna con education tertiary + marital = single ,binaria llamarla TM\n#Tasas de conversión por housing:\n#         conversion_rate_%  total_casos\n#housing                                \n#no                   17.58       338712\n#yes                   7.53       411288\n# crear columna binaria de housing yes o default yes o loan yes llamarla Financia_issues\n#Tasas de conversión por día:\n#           conversion_rate_%  count\n#day_name                           \n#Lunes                  35.81   3890\n#Miércoles              20.42  15827\n#Jueves                 18.60  22270\n#Martes                 17.53  20003\n#Viernes                13.27  30245\n#Domingo                 9.82  28771\n#Sábado                  9.35  30573\n#crear columna binaria para fin de semana ,llamaral Weekend\n#Tasas de conversión por rangos de pdays:\n#                 conversion_rate_%  total_casos\n#pdays_binned                                   \n#51-100                       64.73        12454\n#101-200                      33.92        29690\n#0-50                         19.88          845\n#300+                         10.73        24536\n#201-300                      10.29        10041\n#Never contacted              10.19       672434\n#Tasa conversión nunca contactados: 10.19%\n#Tasa conversión previamente contactados: 28.32%\n# crear columna para pdays = -1 o pdays>200  o previous = 0, binaria 0/1 llamarla Insistencia\n#previous                                \n#0                         10.19       672431\n#1                         25.74        28342\n#2                         26.21        20468\n#3+                        32.37        28759\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:13.437591Z","iopub.execute_input":"2025-08-13T23:58:13.437856Z","iopub.status.idle":"2025-08-13T23:58:13.443581Z","shell.execute_reply.started":"2025-08-13T23:58:13.437836Z","shell.execute_reply":"2025-08-13T23:58:13.442682Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"#pipeline One-hot\n#para transformar train y test , para poder trabajar\n\n# class BankMarketingPreprocessor:\n#     def __init__(self):\n#         self.job_categories = None\n#         self.fitted = False\n    \n#     def fit_transform(self, train_df):\n#         \"\"\"\n#         #Ajusta el preprocessor en los datos de entrenamiento y los transforma\n#         \"\"\"\n#         df = train_df.copy()\n        \n#         # 1. TARGET VARIABLE (ya viene como 0/1, no modificar)\n#         # df['y'] ya está en formato correcto\n        \n#         # 2. VARIABLES BINARIAS (Label Encoding simple)\n#         binary_mappings = {\n#             'default': {'no': 0, 'yes': 1},\n#             'housing': {'no': 0, 'yes': 1}, \n#             'loan': {'no': 0, 'yes': 1}\n#         }\n        \n#         for col, mapping in binary_mappings.items():\n#             df[col] = df[col].map(mapping)\n        \n#         # 3. EDUCATION (Ordinal)\n#         education_mapping = {\n#             'unknown': 0,\n#             'primary': 1, \n#             'secondary': 2, \n#             'tertiary': 3\n#         }\n#         df['education'] = df['education'].map(education_mapping)\n        \n#         # 4. ONE-HOT ENCODING\n#         # Contact (3 categorías -> 2 columnas)\n#         df['contact_cellular'] = (df['contact'] == 'cellular').astype(int)\n#         df['contact_telephone'] = (df['contact'] == 'telephone').astype(int)\n#         # unknown se infiere cuando ambas son 0\n        \n#         # Month (12 categorías -> 11 columnas)\n#         months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', \n#                  'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n        \n#         for month in months[1:]:  # Omitimos 'jan' como referencia\n#             df[f'month_{month}'] = (df['month'] == month).astype(int)\n        \n#         # Poutcome (4 categorías -> 3 columnas)\n#         poutcomes = ['failure', 'other', 'success']  # Omitimos 'unknown' como referencia\n#         for outcome in poutcomes:\n#             df[f'poutcome_{outcome}'] = (df['poutcome'] == outcome).astype(int)\n        \n#         # Job (12 categorías -> 11 columnas) - GUARDAR CATEGORÍAS PARA TEST\n#         self.job_categories = sorted(df['job'].unique())  # Ordenar para consistencia\n#         reference_job = self.job_categories[0]  # Primera categoría como referencia\n        \n#         for job in self.job_categories:\n#             if job != reference_job:\n#                 df[f'job_{job}'] = (df['job'] == job).astype(int)\n        \n#         # Marital (3 categorías -> 2 columnas) \n#         maritals = ['single', 'divorced']  # Omitimos 'married' como referencia\n#         for marital in maritals:\n#             df[f'marital_{marital}'] = (df['marital'] == marital).astype(int)\n        \n#         # 5. MANTENER pdays ORIGINAL\n#         # No hacer nada con pdays - mantenerlo como está (-1 para no contactados)\n        \n#         # 6. ELIMINAR COLUMNAS ORIGINALES CATEGÓRICAS\n#         columns_to_drop = ['job', 'marital', 'contact', 'month', 'poutcome']\n#         df = df.drop(columns=columns_to_drop)\n        \n#         self.fitted = True\n#         return df\n    \n#     def transform(self, test_df):\n#         \"\"\"\n#         #Transforma los datos de test usando los parámetros ajustados en train\n#         \"\"\"\n#         if not self.fitted:\n#             raise ValueError(\"El preprocessor debe ser ajustado primero con fit_transform()\")\n        \n#         df = test_df.copy()\n        \n#         # 1. VARIABLES BINARIAS (mismas que en train)\n#         binary_mappings = {\n#             'default': {'no': 0, 'yes': 1},\n#             'housing': {'no': 0, 'yes': 1}, \n#             'loan': {'no': 0, 'yes': 1}\n#         }\n        \n#         for col, mapping in binary_mappings.items():\n#             df[col] = df[col].map(mapping)\n        \n#         # 2. EDUCATION (Ordinal - mismo que en train)\n#         education_mapping = {\n#             'unknown': 0,\n#             'primary': 1, \n#             'secondary': 2, \n#             'tertiary': 3\n#         }\n#         df['education'] = df['education'].map(education_mapping)\n        \n#         # 3. ONE-HOT ENCODING (mismo que en train)\n#         # Contact\n#         df['contact_cellular'] = (df['contact'] == 'cellular').astype(int)\n#         df['contact_telephone'] = (df['contact'] == 'telephone').astype(int)\n        \n#         # Month (mismos meses que en train)\n#         months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', \n#                  'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n        \n#         for month in months[1:]:  # Omitimos 'jan' como referencia\n#             df[f'month_{month}'] = (df['month'] == month).astype(int)\n        \n#         # Poutcome (mismas categorías que en train)\n#         poutcomes = ['failure', 'other', 'success']  # Omitimos 'unknown' como referencia\n#         for outcome in poutcomes:\n#             df[f'poutcome_{outcome}'] = (df['poutcome'] == outcome).astype(int)\n        \n#         # Job (USAR EXACTAMENTE LAS MISMAS CATEGORÍAS QUE EN TRAIN)\n#         if self.job_categories is None:\n#             raise ValueError(\"Las categorías de job no fueron guardadas durante fit_transform()\")\n        \n#         reference_job = self.job_categories[0]  # Misma referencia que en train\n        \n#         for job in self.job_categories:\n#             if job != reference_job:\n#                 df[f'job_{job}'] = (df['job'] == job).astype(int)\n        \n#         # Marital (mismas categorías que en train)\n#         maritals = ['single', 'divorced']  # Omitimos 'married' como referencia\n#         for marital in maritals:\n#             df[f'marital_{marital}'] = (df['marital'] == marital).astype(int)\n        \n#         # 4. MANTENER pdays ORIGINAL\n#         # No hacer nada con pdays - mantenerlo como está\n        \n#         # 5. ELIMINAR COLUMNAS ORIGINALES CATEGÓRICAS (mismas que en train)\n#         columns_to_drop = ['job', 'marital', 'contact', 'month', 'poutcome']\n#         df = df.drop(columns=columns_to_drop)\n        \n#         return df\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:13.447918Z","iopub.execute_input":"2025-08-13T23:58:13.448457Z","iopub.status.idle":"2025-08-13T23:58:13.463432Z","shell.execute_reply.started":"2025-08-13T23:58:13.448428Z","shell.execute_reply":"2025-08-13T23:58:13.462635Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"#Feat eng avanzado\n\n# Aplicar feature engineering a ambos datasets\nprint(\"Aplicando feature engineering...\")\n\n## TRAIN dataset\n# Interacciones\ntrain['age_duration'] = train['age'] * train['duration']\ntrain['balance_duration'] = train['balance'] * train['duration'] \ntrain['campaign_previous'] = train['campaign'] * train['previous'] # ver si lo elimino\ntrain['pdays_previous'] = np.where(                                # ver si lo elimino\n    (train['pdays'] > 0) & (train['previous'] > 0),\n    train['pdays'] * train['previous'],\n    0\n)\n\n# Ratios\ntrain['balance_per_age'] = train['balance'] / (train['age'] + 1)\ntrain['duration_per_campaign'] = train['duration'] / (train['campaign'] + 1)\n\n## TEST dataset  \n# Interacciones\ntest['age_duration'] = test['age'] * test['duration']\ntest['balance_duration'] = test['balance'] * test['duration'] \ntest['campaign_previous'] = test['campaign'] * test['previous'] # ver si lo elimino\ntest['pdays_previous'] = np.where(                              # ver si lo elimino\n    (test['pdays'] > 0) & (test['previous'] > 0),\n    test['pdays'] * test['previous'],\n    0\n)\n\n# Ratios\ntest['balance_per_age'] = test['balance'] / (test['age'] + 1)\ntest['duration_per_campaign'] = test['duration'] / (test['campaign'] + 1)\n\nprint(\"✓ Feature engineering aplicado a train y test\")\n\n# Quick check de las nuevas features\nnew_features = ['age_duration', 'balance_duration', 'campaign_previous', \n                'pdays_previous', 'balance_per_age', 'duration_per_campaign']\n\nprint(f\"\\n=== NUEVAS FEATURES CREADAS ===\")\nprint(f\"Train shape: {train.shape}\")\nprint(f\"Test shape: {test.shape}\")\n\n# Ver estadísticas básicas de las nuevas features\nprint(f\"\\n=== ESTADÍSTICAS DE NUEVAS FEATURES (TRAIN) ===\")\nprint(train[new_features].describe())\n\n# Ver correlaciones con target \nif 'y' in train.columns:  #\n    print(f\"\\n=== CORRELACIONES CON TARGET ===\")\n    for feat in new_features:\n        corr = train[feat].corr(train['y'])\n        print(f\"{feat}: {corr:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:13.464304Z","iopub.execute_input":"2025-08-13T23:58:13.464598Z","iopub.status.idle":"2025-08-13T23:58:13.847337Z","shell.execute_reply.started":"2025-08-13T23:58:13.464572Z","shell.execute_reply":"2025-08-13T23:58:13.846458Z"}},"outputs":[{"name":"stdout","text":"Aplicando feature engineering...\n✓ Feature engineering aplicado a train y test\n\n=== NUEVAS FEATURES CREADAS ===\nTrain shape: (750000, 24)\nTest shape: (250000, 23)\n\n=== ESTADÍSTICAS DE NUEVAS FEATURES (TRAIN) ===\n        age_duration  balance_duration  campaign_previous  pdays_previous  \\\ncount  750000.000000      7.500000e+05      750000.000000   750000.000000   \nmean    10474.458324      3.932599e+05           0.672360       64.725656   \nstd     11869.205039      1.336345e+06           4.727852      320.247210   \nmin        30.000000     -8.917128e+06           0.000000        0.000000   \n25%      3567.000000      0.000000e+00           0.000000        0.000000   \n50%      5499.000000      8.025000e+04           0.000000        0.000000   \n75%     13260.000000      3.239100e+05           0.000000        0.000000   \nmax    308889.000000      1.205648e+08        1032.000000    31898.000000   \n\n       balance_per_age  duration_per_campaign  \ncount    750000.000000          750000.000000  \nmean         29.555181              93.503746  \nstd          68.327356             107.844920  \nmin        -334.125000               0.117647  \n25%           0.000000              27.428571  \n50%          15.720000              51.333333  \n75%          34.233333             114.000000  \nmax        3514.892857            2459.000000  \n\n=== CORRELACIONES CON TARGET ===\nage_duration: 0.490\nbalance_duration: 0.250\ncampaign_previous: 0.052\npdays_previous: 0.064\nbalance_per_age: 0.129\nduration_per_campaign: 0.504\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"#pipeline One-hot V2\n\nclass BankMarketingPreprocessor:\n    def __init__(self):\n        self.job_categories = None\n        self.fitted = False\n\n    def _apply_common_transformations(self, df_original):\n        \"\"\"\n        MÉTODO PRIVADO: Contiene TODAS las transformaciones comunes\n        para evitar duplicación y errores.\n        \"\"\"\n        df = df_original.copy()\n\n        # --- Feature Engineering ---\n        month_success_rates = {\n            'mar': 0.571355, 'sep': 0.534755, 'dec': 0.513291, 'oct': 0.490004,\n            'apr': 0.235654, 'feb': 0.206801, 'jan': 0.124148, 'aug': 0.112161,\n            'nov': 0.109806, 'jun': 0.103726, 'jul': 0.090847, 'may': 0.071354\n        }\n        df['month_success_rate'] = df['month'].map(month_success_rates)\n        df['Non_interested'] = ((df['balance'] < 565) & (df['duration'] < 203.8) & (df['contact'] == 'unknown')).astype(int)\n        df['S_R_U'] = (((df['age'] < 25) | (df['age'] >= 65)) & (df['job'].isin(['student', 'retired', 'unemployed']))).astype(int)\n        df['TM'] = ((df['education'] == 'tertiary') & (df['marital'] == 'single')).astype(int)\n        df['Financial_issues'] = ((df['housing'] == 'yes') | (df['default'] == 'yes') | (df['loan'] == 'yes')).astype(int)\n        \n        day_mapping = {1: 'Lunes', 2: 'Martes', 3: 'Miércoles', 4: 'Jueves', 5: 'Viernes', 6: 'Sábado', 7: 'Domingo'}\n        df['day_name'] = df['day'].map(day_mapping) # Columna auxiliar\n        df['Weekend'] = (df['day_name'].isin(['Viernes','Sábado', 'Domingo'])).astype(int)\n        \n        df['Insistencia'] = ((df['pdays'] == -1) | (df['pdays'] > 200) | (df['previous'] == 0)).astype(int)\n\n        # --- Codificación de Variables ---\n        binary_mappings = {'default': {'no': 0, 'yes': 1}, 'housing': {'no': 0, 'yes': 1}, 'loan': {'no': 0, 'yes': 1}}\n        for col, mapping in binary_mappings.items():\n            df[col] = df[col].map(mapping)\n\n        education_mapping = {'unknown': 0, 'primary': 1, 'secondary': 2, 'tertiary': 3}\n        df['education'] = df['education'].map(education_mapping)\n\n        # --- One-Hot Encoding ---\n        df['contact_cellular'] = (df['contact'] == 'cellular').astype(int)\n        df['contact_telephone'] = (df['contact'] == 'telephone').astype(int)\n        \n        months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n        for month in months[1:]:\n            df[f'month_{month}'] = (df['month'] == month).astype(int)\n            \n        poutcomes = ['failure', 'other', 'success']\n        for outcome in poutcomes:\n            df[f'poutcome_{outcome}'] = (df['poutcome'] == outcome).astype(int)\n        \n        maritals = ['single', 'divorced']\n        for marital in maritals:\n            df[f'marital_{marital}'] = (df['marital'] == marital).astype(int)\n        \n        # OHE para 'job' usando las categorías guardadas del set de train\n        reference_job = self.job_categories[0]\n        for job in self.job_categories:\n            if job != reference_job:\n                df[f'job_{job}'] = (df['job'] == job).astype(int)\n        \n        # --- Limpieza Final ---\n        # Se eliminan las columnas originales y la auxiliar 'day_name'\n        columns_to_drop = ['job', 'marital', 'contact', 'month', 'poutcome', 'day_name']\n        df = df.drop(columns=columns_to_drop)\n        \n        return df\n\n    def fit_transform(self, train_df):\n        \"\"\"Ajusta y transforma los datos de entrenamiento.\"\"\"\n        # APRENDE las categorías de 'job' del set de entrenamiento\n        self.job_categories = sorted(train_df['job'].unique())\n        \n        # APLICA todas las transformaciones llamando al método común\n        df_transformed = self._apply_common_transformations(train_df)\n        \n        self.fitted = True\n        return df_transformed\n        \n    def transform(self, test_df):\n        \"\"\"Transforma los datos de test.\"\"\"\n        if not self.fitted:\n            raise ValueError(\"El preprocessor debe ser ajustado primero con fit_transform()\")\n        \n        # APLICA EXACTAMENTE las mismas transformaciones que en train\n        df_transformed = self._apply_common_transformations(test_df)\n        \n        return df_transformed\n# NUEVAS FEATURES AGREGADAS:\n# - month_success_rate: Tasa de éxito histórica por mes (0-1)\n# - Non_interested: Clientes con bajo balance, duración corta y contacto desconocido\n# - S_R_U: Estudiantes, jubilados o desempleados jóvenes (<25) o mayores (>=65)\n# - TM: Educación terciaria y solteros\n# - Financial_issues: Tienen algún tipo de préstamo o problema crediticio\n# - Weekend: Contactados en fin de semana\n# - Insistencia: Casos de baja insistencia (nunca contactados, hace mucho tiempo, o sin contactos previos)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:13.848275Z","iopub.execute_input":"2025-08-13T23:58:13.848518Z","iopub.status.idle":"2025-08-13T23:58:13.864684Z","shell.execute_reply.started":"2025-08-13T23:58:13.848499Z","shell.execute_reply":"2025-08-13T23:58:13.863917Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"preprocessor = BankMarketingPreprocessor()\n              \nX_train_p = preprocessor.fit_transform(train)\nX_test_p = preprocessor.transform(test)\n\ny_train_f = X_train_p[\"y\"]\nX_train_f = X_train_p.drop(\"y\", axis=1)\n\nprint(f\"Shape final train: {X_train_f.shape}\")\nprint(f\"Shape final test: {X_test_p.shape}\")\nprint(f\"Columnas finales: {list(X_train_f.columns)}\")\nprint(f\"Columnas finales: {list(X_test_p.columns)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:13.865487Z","iopub.execute_input":"2025-08-13T23:58:13.865742Z","iopub.status.idle":"2025-08-13T23:58:18.017816Z","shell.execute_reply.started":"2025-08-13T23:58:13.865722Z","shell.execute_reply":"2025-08-13T23:58:18.016863Z"}},"outputs":[{"name":"stdout","text":"Shape final train: (750000, 54)\nShape final test: (250000, 54)\nColumnas finales: ['id', 'age', 'education', 'default', 'balance', 'housing', 'loan', 'day', 'duration', 'campaign', 'pdays', 'previous', 'age_duration', 'balance_duration', 'campaign_previous', 'pdays_previous', 'balance_per_age', 'duration_per_campaign', 'month_success_rate', 'Non_interested', 'S_R_U', 'TM', 'Financial_issues', 'Weekend', 'Insistencia', 'contact_cellular', 'contact_telephone', 'month_feb', 'month_mar', 'month_apr', 'month_may', 'month_jun', 'month_jul', 'month_aug', 'month_sep', 'month_oct', 'month_nov', 'month_dec', 'poutcome_failure', 'poutcome_other', 'poutcome_success', 'marital_single', 'marital_divorced', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'job_unknown']\nColumnas finales: ['id', 'age', 'education', 'default', 'balance', 'housing', 'loan', 'day', 'duration', 'campaign', 'pdays', 'previous', 'age_duration', 'balance_duration', 'campaign_previous', 'pdays_previous', 'balance_per_age', 'duration_per_campaign', 'month_success_rate', 'Non_interested', 'S_R_U', 'TM', 'Financial_issues', 'Weekend', 'Insistencia', 'contact_cellular', 'contact_telephone', 'month_feb', 'month_mar', 'month_apr', 'month_may', 'month_jun', 'month_jul', 'month_aug', 'month_sep', 'month_oct', 'month_nov', 'month_dec', 'poutcome_failure', 'poutcome_other', 'poutcome_success', 'marital_single', 'marital_divorced', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'job_unknown']\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"X_train_p.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:18.018753Z","iopub.execute_input":"2025-08-13T23:58:18.018981Z","iopub.status.idle":"2025-08-13T23:58:18.040598Z","shell.execute_reply.started":"2025-08-13T23:58:18.018962Z","shell.execute_reply":"2025-08-13T23:58:18.039519Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"   id  age  education  default  balance  housing  loan  day  duration  \\\n0   0   42          2        0        7        0     0   25       117   \n1   1   38          2        0      514        0     0   18       185   \n2   2   36          2        0      602        1     0   14       111   \n3   3   27          2        0       34        1     0   28        10   \n4   4   26          2        0      889        1     0    3       902   \n\n   campaign  pdays  previous  y  age_duration  balance_duration  \\\n0         3     -1         0  0          4914               819   \n1         1     -1         0  0          7030             95090   \n2         2     -1         0  0          3996             66822   \n3         2     -1         0  0           270               340   \n4         1     -1         0  1         23452            801878   \n\n   campaign_previous  pdays_previous  balance_per_age  duration_per_campaign  \\\n0                  0               0         0.162791              29.250000   \n1                  0               0        13.179487              92.500000   \n2                  0               0        16.270270              37.000000   \n3                  0               0         1.214286               3.333333   \n4                  0               0        32.925926             451.000000   \n\n   month_success_rate  Non_interested  S_R_U  TM  Financial_issues  Weekend  \\\n0            0.112161               0      0   0                 0        0   \n1            0.103726               1      0   0                 0        0   \n2            0.071354               0      0   0                 1        0   \n3            0.071354               1      0   0                 1        0   \n4            0.206801               0      0   0                 1        0   \n\n   Insistencia  contact_cellular  contact_telephone  month_feb  month_mar  \\\n0            1                 1                  0          0          0   \n1            1                 0                  0          0          0   \n2            1                 0                  0          0          0   \n3            1                 0                  0          0          0   \n4            1                 1                  0          1          0   \n\n   month_apr  month_may  month_jun  month_jul  month_aug  month_sep  \\\n0          0          0          0          0          1          0   \n1          0          0          1          0          0          0   \n2          0          1          0          0          0          0   \n3          0          1          0          0          0          0   \n4          0          0          0          0          0          0   \n\n   month_oct  month_nov  month_dec  poutcome_failure  poutcome_other  \\\n0          0          0          0                 0               0   \n1          0          0          0                 0               0   \n2          0          0          0                 0               0   \n3          0          0          0                 0               0   \n4          0          0          0                 0               0   \n\n   poutcome_success  marital_single  marital_divorced  job_blue-collar  \\\n0                 0               0                 0                0   \n1                 0               0                 0                1   \n2                 0               0                 0                1   \n3                 0               1                 0                0   \n4                 0               0                 0                0   \n\n   job_entrepreneur  job_housemaid  job_management  job_retired  \\\n0                 0              0               0            0   \n1                 0              0               0            0   \n2                 0              0               0            0   \n3                 0              0               0            0   \n4                 0              0               0            0   \n\n   job_self-employed  job_services  job_student  job_technician  \\\n0                  0             0            0               1   \n1                  0             0            0               0   \n2                  0             0            0               0   \n3                  0             0            1               0   \n4                  0             0            0               1   \n\n   job_unemployed  job_unknown  \n0               0            0  \n1               0            0  \n2               0            0  \n3               0            0  \n4               0            0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>day</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>y</th>\n      <th>age_duration</th>\n      <th>balance_duration</th>\n      <th>campaign_previous</th>\n      <th>pdays_previous</th>\n      <th>balance_per_age</th>\n      <th>duration_per_campaign</th>\n      <th>month_success_rate</th>\n      <th>Non_interested</th>\n      <th>S_R_U</th>\n      <th>TM</th>\n      <th>Financial_issues</th>\n      <th>Weekend</th>\n      <th>Insistencia</th>\n      <th>contact_cellular</th>\n      <th>contact_telephone</th>\n      <th>month_feb</th>\n      <th>month_mar</th>\n      <th>month_apr</th>\n      <th>month_may</th>\n      <th>month_jun</th>\n      <th>month_jul</th>\n      <th>month_aug</th>\n      <th>month_sep</th>\n      <th>month_oct</th>\n      <th>month_nov</th>\n      <th>month_dec</th>\n      <th>poutcome_failure</th>\n      <th>poutcome_other</th>\n      <th>poutcome_success</th>\n      <th>marital_single</th>\n      <th>marital_divorced</th>\n      <th>job_blue-collar</th>\n      <th>job_entrepreneur</th>\n      <th>job_housemaid</th>\n      <th>job_management</th>\n      <th>job_retired</th>\n      <th>job_self-employed</th>\n      <th>job_services</th>\n      <th>job_student</th>\n      <th>job_technician</th>\n      <th>job_unemployed</th>\n      <th>job_unknown</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25</td>\n      <td>117</td>\n      <td>3</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4914</td>\n      <td>819</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.162791</td>\n      <td>29.250000</td>\n      <td>0.112161</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>38</td>\n      <td>2</td>\n      <td>0</td>\n      <td>514</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>185</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7030</td>\n      <td>95090</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.179487</td>\n      <td>92.500000</td>\n      <td>0.103726</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>36</td>\n      <td>2</td>\n      <td>0</td>\n      <td>602</td>\n      <td>1</td>\n      <td>0</td>\n      <td>14</td>\n      <td>111</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3996</td>\n      <td>66822</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16.270270</td>\n      <td>37.000000</td>\n      <td>0.071354</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>27</td>\n      <td>2</td>\n      <td>0</td>\n      <td>34</td>\n      <td>1</td>\n      <td>0</td>\n      <td>28</td>\n      <td>10</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>270</td>\n      <td>340</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.214286</td>\n      <td>3.333333</td>\n      <td>0.071354</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>26</td>\n      <td>2</td>\n      <td>0</td>\n      <td>889</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>902</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>23452</td>\n      <td>801878</td>\n      <td>0</td>\n      <td>0</td>\n      <td>32.925926</td>\n      <td>451.000000</td>\n      <td>0.206801</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"X_test_p.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:18.041535Z","iopub.execute_input":"2025-08-13T23:58:18.041989Z","iopub.status.idle":"2025-08-13T23:58:18.130613Z","shell.execute_reply.started":"2025-08-13T23:58:18.041959Z","shell.execute_reply":"2025-08-13T23:58:18.129836Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"       id  age  education  default  balance  housing  loan  day  duration  \\\n0  750000   32          2        0     1397        1     0   21       224   \n1  750001   44          3        0       23        1     0    3       586   \n2  750002   36          1        0       46        1     1   13       111   \n3  750003   58          2        0    -1380        1     1   29       125   \n4  750004   28          2        0     1950        1     0   22       181   \n\n   campaign  pdays  previous  age_duration  balance_duration  \\\n0         1     -1         0          7168            312928   \n1         2     -1         0         25784             13478   \n2         2     -1         0          3996              5106   \n3         1     -1         0          7250           -172500   \n4         1     -1         0          5068            352950   \n\n   campaign_previous  pdays_previous  balance_per_age  duration_per_campaign  \\\n0                  0               0        42.333333             112.000000   \n1                  0               0         0.511111             195.333333   \n2                  0               0         1.243243              37.000000   \n3                  0               0       -23.389831              62.500000   \n4                  0               0        67.241379              90.500000   \n\n   month_success_rate  Non_interested  S_R_U  TM  Financial_issues  Weekend  \\\n0            0.071354               0      0   0                 1        0   \n1            0.235654               0      0   0                 1        0   \n2            0.071354               0      0   0                 1        0   \n3            0.071354               1      0   0                 1        0   \n4            0.090847               0      0   0                 1        0   \n\n   Insistencia  contact_cellular  contact_telephone  month_feb  month_mar  \\\n0            1                 0                  0          0          0   \n1            1                 1                  0          0          0   \n2            1                 1                  0          0          0   \n3            1                 0                  0          0          0   \n4            1                 1                  0          0          0   \n\n   month_apr  month_may  month_jun  month_jul  month_aug  month_sep  \\\n0          0          1          0          0          0          0   \n1          1          0          0          0          0          0   \n2          0          1          0          0          0          0   \n3          0          1          0          0          0          0   \n4          0          0          0          1          0          0   \n\n   month_oct  month_nov  month_dec  poutcome_failure  poutcome_other  \\\n0          0          0          0                 0               0   \n1          0          0          0                 0               0   \n2          0          0          0                 0               0   \n3          0          0          0                 0               0   \n4          0          0          0                 0               0   \n\n   poutcome_success  marital_single  marital_divorced  job_blue-collar  \\\n0                 0               0                 0                1   \n1                 0               0                 0                0   \n2                 0               0                 0                0   \n3                 0               0                 0                1   \n4                 0               1                 0                0   \n\n   job_entrepreneur  job_housemaid  job_management  job_retired  \\\n0                 0              0               0            0   \n1                 0              0               1            0   \n2                 0              0               0            0   \n3                 0              0               0            0   \n4                 0              0               0            0   \n\n   job_self-employed  job_services  job_student  job_technician  \\\n0                  0             0            0               0   \n1                  0             0            0               0   \n2                  1             0            0               0   \n3                  0             0            0               0   \n4                  0             0            0               1   \n\n   job_unemployed  job_unknown  \n0               0            0  \n1               0            0  \n2               0            0  \n3               0            0  \n4               0            0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>education</th>\n      <th>default</th>\n      <th>balance</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>day</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>age_duration</th>\n      <th>balance_duration</th>\n      <th>campaign_previous</th>\n      <th>pdays_previous</th>\n      <th>balance_per_age</th>\n      <th>duration_per_campaign</th>\n      <th>month_success_rate</th>\n      <th>Non_interested</th>\n      <th>S_R_U</th>\n      <th>TM</th>\n      <th>Financial_issues</th>\n      <th>Weekend</th>\n      <th>Insistencia</th>\n      <th>contact_cellular</th>\n      <th>contact_telephone</th>\n      <th>month_feb</th>\n      <th>month_mar</th>\n      <th>month_apr</th>\n      <th>month_may</th>\n      <th>month_jun</th>\n      <th>month_jul</th>\n      <th>month_aug</th>\n      <th>month_sep</th>\n      <th>month_oct</th>\n      <th>month_nov</th>\n      <th>month_dec</th>\n      <th>poutcome_failure</th>\n      <th>poutcome_other</th>\n      <th>poutcome_success</th>\n      <th>marital_single</th>\n      <th>marital_divorced</th>\n      <th>job_blue-collar</th>\n      <th>job_entrepreneur</th>\n      <th>job_housemaid</th>\n      <th>job_management</th>\n      <th>job_retired</th>\n      <th>job_self-employed</th>\n      <th>job_services</th>\n      <th>job_student</th>\n      <th>job_technician</th>\n      <th>job_unemployed</th>\n      <th>job_unknown</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>750000</td>\n      <td>32</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1397</td>\n      <td>1</td>\n      <td>0</td>\n      <td>21</td>\n      <td>224</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>7168</td>\n      <td>312928</td>\n      <td>0</td>\n      <td>0</td>\n      <td>42.333333</td>\n      <td>112.000000</td>\n      <td>0.071354</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>750001</td>\n      <td>44</td>\n      <td>3</td>\n      <td>0</td>\n      <td>23</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>586</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>25784</td>\n      <td>13478</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.511111</td>\n      <td>195.333333</td>\n      <td>0.235654</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>750002</td>\n      <td>36</td>\n      <td>1</td>\n      <td>0</td>\n      <td>46</td>\n      <td>1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>111</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>3996</td>\n      <td>5106</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.243243</td>\n      <td>37.000000</td>\n      <td>0.071354</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>750003</td>\n      <td>58</td>\n      <td>2</td>\n      <td>0</td>\n      <td>-1380</td>\n      <td>1</td>\n      <td>1</td>\n      <td>29</td>\n      <td>125</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>7250</td>\n      <td>-172500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-23.389831</td>\n      <td>62.500000</td>\n      <td>0.071354</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>750004</td>\n      <td>28</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1950</td>\n      <td>1</td>\n      <td>0</td>\n      <td>22</td>\n      <td>181</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>5068</td>\n      <td>352950</td>\n      <td>0</td>\n      <td>0</td>\n      <td>67.241379</td>\n      <td>90.500000</td>\n      <td>0.090847</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"# Guardar IDs antes de eliminar\ntrain_ids = X_train_f['id'].copy()\ntest_ids = X_test_p['id'].copy()\n\n# Eliminar ID de los datasets\nX_train_final = X_train_f.drop('id', axis=1)  # 40 columnas\nX_test_final = X_test_p.drop('id', axis=1)    # 40 columnas\n\nprint(f\"Train shape sin ID: {X_train_final.shape}\")\nprint(f\"Test shape sin ID: {X_test_final.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:18.131378Z","iopub.execute_input":"2025-08-13T23:58:18.131595Z","iopub.status.idle":"2025-08-13T23:58:18.528899Z","shell.execute_reply.started":"2025-08-13T23:58:18.131576Z","shell.execute_reply":"2025-08-13T23:58:18.528046Z"}},"outputs":[{"name":"stdout","text":"Train shape sin ID: (750000, 53)\nTest shape sin ID: (250000, 53)\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"%%time\nxgb_model11 = xgb.XGBClassifier(\n        n_estimators=475,\n        learning_rate=0.7180,\n        max_depth=9,\n        subsample=0.8006,\n        colsample_bytree=0.8169,\n        colsample_bylevel=0.7323,\n        min_child_weight=7,\n        gamma=0.4794,\n        reg_alpha=0.6923,\n        reg_lambda=0.9114,\n        random_state=42,\n        n_jobs=-1,\n        eval_metric='auc',\n        use_label_encoder=False,\n        verbosity=2\n)    \n#Entrenar\nxgb_model11.fit(X_train_final, y_train_f)\n\n# Hacer predicciones\ny_test_pred_xgb11 = xgb_model11.predict_proba(X_test_final)[:, 1]\n\n# #Submission\n# submission = pd.DataFrame({\n#    'id': test_ids,\n#    'y': y_test_pred_xgb7\n# })\n# submission.to_csv('submission.csv', index=False)\n\n# submission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:59:16.207129Z","iopub.execute_input":"2025-08-13T23:59:16.207419Z","iopub.status.idle":"2025-08-14T00:00:11.296337Z","shell.execute_reply.started":"2025-08-13T23:59:16.207397Z","shell.execute_reply":"2025-08-14T00:00:11.295415Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 3min 17s, sys: 533 ms, total: 3min 17s\nWall time: 55.1 s\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"%%time\nfrom lightgbm import LGBMClassifier\n\nlgb_model11 = LGBMClassifier(\n    random_state=42,\n    n_jobs=-5,\n    objective='binary',  \n    boosting_type='gbdt',\n    metric='binary_logloss',\n    n_estimators=366,\n    max_depth=-1,\n    learning_rate=0.0702,\n    num_leaves=148,\n    subsample=0.9878,\n    colsample_bytree=0.7205,\n    min_child_samples=36,\n    reg_alpha=0.3872,\n    reg_lambda=0.9090\n)\n\n# Entrenar\nlgb_model11.fit(X_train_final, y_train_f)\n\n# Hacer predicciones\ny_test_pred_lgb11 = lgb_model11.predict_proba(X_test_final)[:, 1]\n\n# #Submission\n# submission = pd.DataFrame({\n#    'id': test_ids,\n#    'y': y_test_pred\n# })\n# submission.to_csv('submission.csv', index=False)\n\n# submission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T00:00:11.297780Z","iopub.execute_input":"2025-08-14T00:00:11.298116Z","iopub.status.idle":"2025-08-14T00:01:06.494371Z","shell.execute_reply.started":"2025-08-14T00:00:11.298086Z","shell.execute_reply":"2025-08-14T00:01:06.493525Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 90488, number of negative: 659512\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.157140 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2418\n[LightGBM] [Info] Number of data points in the train set: 750000, number of used features: 53\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120651 -> initscore=-1.986283\n[LightGBM] [Info] Start training from score -1.986283\nCPU times: user 54.6 s, sys: 548 ms, total: 55.1 s\nWall time: 55.2 s\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_predict\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T00:01:06.495181Z","iopub.execute_input":"2025-08-14T00:01:06.495425Z","iopub.status.idle":"2025-08-14T00:01:06.499356Z","shell.execute_reply.started":"2025-08-14T00:01:06.495406Z","shell.execute_reply":"2025-08-14T00:01:06.498575Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"#meta learner\nprint(\"Generando predicciones out-of-fold...\")\n\n#\nxgb_oof = cross_val_predict(\n    xgb_model11, \n    X_train_final, \n    y_train_f, \n    cv=5, \n    method='predict_proba'\n)[:, 1]\n\n#\nlgb_oof = cross_val_predict(\n    lgb_model11, \n    X_train_final, \n    y_train_f, \n    cv=5, \n    method='predict_proba'\n)[:, 1]\n\nprint(\"✓ Predicciones out-of-fold generadas\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T00:01:06.501330Z","iopub.execute_input":"2025-08-14T00:01:06.501567Z","iopub.status.idle":"2025-08-14T00:07:38.868161Z","shell.execute_reply.started":"2025-08-14T00:01:06.501549Z","shell.execute_reply":"2025-08-14T00:07:38.867390Z"}},"outputs":[{"name":"stdout","text":"Generando predicciones out-of-fold...\n[LightGBM] [Info] Number of positive: 72391, number of negative: 527609\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124213 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2418\n[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 53\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120652 -> initscore=-1.986273\n[LightGBM] [Info] Start training from score -1.986273\n[LightGBM] [Info] Number of positive: 72391, number of negative: 527609\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122939 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2415\n[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 53\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120652 -> initscore=-1.986273\n[LightGBM] [Info] Start training from score -1.986273\n[LightGBM] [Info] Number of positive: 72390, number of negative: 527610\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126387 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2412\n[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 53\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120650 -> initscore=-1.986289\n[LightGBM] [Info] Start training from score -1.986289\n[LightGBM] [Info] Number of positive: 72390, number of negative: 527610\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122071 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2410\n[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 53\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120650 -> initscore=-1.986289\n[LightGBM] [Info] Start training from score -1.986289\n[LightGBM] [Info] Number of positive: 72390, number of negative: 527610\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122550 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 2413\n[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 53\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120650 -> initscore=-1.986289\n[LightGBM] [Info] Start training from score -1.986289\n✓ Predicciones out-of-fold generadas\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# Combinar predicciones en una matriz\nbase_predictions = np.column_stack([xgb_oof, lgb_oof])\nprint(f\"Shape de base_predictions: {base_predictions.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T00:07:38.868836Z","iopub.execute_input":"2025-08-14T00:07:38.869068Z","iopub.status.idle":"2025-08-14T00:07:38.877145Z","shell.execute_reply.started":"2025-08-14T00:07:38.869049Z","shell.execute_reply":"2025-08-14T00:07:38.876423Z"}},"outputs":[{"name":"stdout","text":"Shape de base_predictions: (750000, 2)\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# Entrenar meta-learner\nmeta_learner = LogisticRegression(random_state=42)\nmeta_learner.fit(base_predictions, y_train_f)\n\nprint(\"✓ Meta-learner entrenado\")\nprint(f\"Coeficientes: {meta_learner.coef_[0]}\")\nprint(f\"Intercept: {meta_learner.intercept_[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T00:07:38.877945Z","iopub.execute_input":"2025-08-14T00:07:38.878264Z","iopub.status.idle":"2025-08-14T00:07:39.634247Z","shell.execute_reply.started":"2025-08-14T00:07:38.878239Z","shell.execute_reply":"2025-08-14T00:07:39.630876Z"}},"outputs":[{"name":"stdout","text":"✓ Meta-learner entrenado\nCoeficientes: [0.43596003 7.14952188]\nIntercept: -3.9948940808938915\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# Predicciones base en test\nxgb_test_pred = y_test_pred_xgb11\nlgb_test_pred = y_test_pred_lgb11 \n\n# Combinar predicciones de test\nbase_predictions_test = np.column_stack([xgb_test_pred, lgb_test_pred])\n\n# Predicción final del meta-learner\ny_test_pred_meta = meta_learner.predict_proba(base_predictions_test)[:, 1]\n\nprint(\"✓ Predicciones finales generadas\")\nprint(f\"Rango de predicciones: [{y_test_pred_meta.min():.4f}, {y_test_pred_meta.max():.4f}]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T00:07:39.635159Z","iopub.execute_input":"2025-08-14T00:07:39.635842Z","iopub.status.idle":"2025-08-14T00:07:39.672545Z","shell.execute_reply.started":"2025-08-14T00:07:39.635816Z","shell.execute_reply":"2025-08-14T00:07:39.671872Z"}},"outputs":[{"name":"stdout","text":"✓ Predicciones finales generadas\nRango de predicciones: [0.0181, 0.9727]\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# Comparar con predicciones individuales\nprint(\"\\n=== COMPARACIÓN DE PREDICCIONES ===\")\nprint(f\"XGBoost promedio: {xgb_test_pred.mean():.4f}\")\nprint(f\"LightGBM promedio: {lgb_test_pred.mean():.4f}\")\nprint(f\"Meta-learner promedio: {y_test_pred_meta.mean():.4f}\")\n\n# Simple average para comparar\nsimple_average = (xgb_test_pred + lgb_test_pred) / 2\nprint(f\"Simple average promedio: {simple_average.mean():.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T00:07:39.673139Z","iopub.execute_input":"2025-08-14T00:07:39.673380Z","iopub.status.idle":"2025-08-14T00:07:39.683513Z","shell.execute_reply.started":"2025-08-14T00:07:39.673359Z","shell.execute_reply":"2025-08-14T00:07:39.682742Z"}},"outputs":[{"name":"stdout","text":"\n=== COMPARACIÓN DE PREDICCIONES ===\nXGBoost promedio: 0.1192\nLightGBM promedio: 0.1202\nMeta-learner promedio: 0.1207\nSimple average promedio: 0.1197\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":" # Crear el submission\n submission = pd.DataFrame({\n     'id': test_ids,\n     'y': y_test_pred_meta\n })\n submission.to_csv('submission.csv', index=False)\n\n submission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T00:07:39.685874Z","iopub.execute_input":"2025-08-14T00:07:39.686167Z","iopub.status.idle":"2025-08-14T00:07:40.294044Z","shell.execute_reply.started":"2025-08-14T00:07:39.686144Z","shell.execute_reply":"2025-08-14T00:07:40.293247Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"       id         y\n0  750000  0.018342\n1  750001  0.039459\n2  750002  0.018110\n3  750003  0.018087\n4  750004  0.020608","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>750000</td>\n      <td>0.018342</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>750001</td>\n      <td>0.039459</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>750002</td>\n      <td>0.018110</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>750003</td>\n      <td>0.018087</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>750004</td>\n      <td>0.020608</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"# # Ensemble simple promediando probabilidades\n# y_test_pred_ensemble = (y_test_pred_lgb5 + y_test_pred_xgb7) / 2\n\n# # Crear el submission\n# submission = pd.DataFrame({\n#     'id': test_ids,\n#     'y': y_test_pred_ensemble\n# })\n# submission.to_csv('submission.csv', index=False)\n\n# submission.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:18.559954Z","iopub.status.idle":"2025-08-13T23:58:18.560334Z","shell.execute_reply.started":"2025-08-13T23:58:18.560155Z","shell.execute_reply":"2025-08-13T23:58:18.560171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T00:08:23.111484Z","iopub.execute_input":"2025-08-14T00:08:23.111858Z","iopub.status.idle":"2025-08-14T00:08:23.141596Z","shell.execute_reply.started":"2025-08-14T00:08:23.111834Z","shell.execute_reply":"2025-08-14T00:08:23.140686Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"                  id              y\ncount  250000.000000  250000.000000\nmean   874999.500000       0.120742\nstd     72168.927986       0.253060\nmin    750000.000000       0.018079\n25%    812499.750000       0.018127\n50%    874999.500000       0.018321\n75%    937499.250000       0.030950\nmax    999999.000000       0.972672","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>874999.500000</td>\n      <td>0.120742</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>72168.927986</td>\n      <td>0.253060</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>750000.000000</td>\n      <td>0.018079</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>812499.750000</td>\n      <td>0.018127</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>874999.500000</td>\n      <td>0.018321</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>937499.250000</td>\n      <td>0.030950</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>999999.000000</td>\n      <td>0.972672</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"#v1 150 iteraciones  CV Score: 0.9613 en competencia 0.89948 ,el primero tiene 0.97778 7/8/2025\n#rf1 = RandomForestClassifier( #rf target encod 150 iter             \n#    n_estimators=100,                   #\n#    min_samples_split=500,              #\n#    min_samples_leaf=200,               #\n#    max_features=0.3,                   #\n#    max_depth= None,                    #\n#    criterion = \"entropy\",              #\n#    bootstrap = False,                  #\n#    random_state=42,                    #\n#    n_jobs=-1,                          #\n#    class_weight='balanced'             #\n#    )\n\"\"\"=== FEATURE IMPORTANCE (TOP 10) ===\n             feature  importance\n7           duration    0.647334\n3            balance    0.082880\n26  poutcome_success    0.040380\n11  contact_cellular    0.038691\n4            housing    0.037123\n9              pdays    0.020095\n0                age    0.016717\n6                day    0.014675\n14         month_mar    0.013597\n10          previous    0.009041\n\"\"\"\n#v2 XGB 250 iteraciones CV Score: 0.9676 en competencia 0.96850\n#xgb_model1 = xgb.XGBClassifier(\n#        n_estimators=366,              #\n#        learning_rate=0.1316,          #\n#        max_depth=8,                   #\n#        subsample=0.8724,              #\n#        colsample_bytree=0.7738,       #\n#        colsample_bylevel=0.7321,      #\n#        min_child_weight=4,            #\n#        gamma=0.1268,                  #\n#        reg_alpha=0.8228,              #\n#        reg_lambda=0.7442,             #\n#        random_state=42,               #\n#        n_jobs=-1,                     #\n#        eval_metric='auc',             #\n#        use_label_encoder=False,       #\n#        verbosity=0                    #\n#) \n\"\"\"\ntarget Encoding v1 rfe\n=== MEJORES PARÁMETROS ===\n{'n_estimators': 200, 'min_samples_split': 100, 'min_samples_leaf': 50, 'max_features': 0.3, 'max_depth': 20, 'criterion': 'gini',\n 'bootstrap': False}\n\n=== MEJOR SCORE (AUC) ===\nCV Score: 0.9620\n\n=== FEATURE IMPORTANCE (TOP 10) ===\n                 feature  importance\n7               duration    0.651461\n3                balance    0.076133\n18  month_target_encoded    0.071657\n15      poutcome_success    0.038616\n11      contact_cellular    0.034448\n4                housing    0.033808\n6                    day    0.017222\n9                  pdays    0.015846\n0                    age    0.013047\n16    job_target_encoded    0.011721\n\"\"\"\n\n#v3 xgb 2500 iteraciones One hot y xgb 2500 iteracion Target Encod , CV Score: 0.9676 en One-hot y target, en competencia 0.96888\n# si o si ver de feature eng y/o una NN para continuar\n# Probe NN , varias estructuras y no es viable para nada ,en competencia lograba 0.82 promedio , muy mal\n#xgb_model2 = xgb.XGBClassifier(\n#        n_estimators=475,          # 424\n#        learning_rate=0.0718,      # 0.0896\n#        max_depth=9,               # 9\n#        subsample=0.8006,          # 0.9350\n#        colsample_bytree=0.8169,   # 0.7346\n#        colsample_bylevel=0.7323,  # 0.7502\n#        min_child_weight=7,        # 4\n#        gamma=0.4794,              # 0.2506\n#        reg_alpha=0.6923,          # 0.6156\n#        reg_lambda=0.9114,         # 0.8680\n#        random_state=42,           # 42\n#        n_jobs=-1,                 #\n#        eval_metric='auc',         #\n#        use_label_encoder=False,   #\n#        verbosity=0                #\n#)\n#Mejor score (CV): 0.9678\n#   Feature Importance XGB\n# 26   poutcome_success    0.295378\n# 14          month_mar    0.095745\n# 7            duration    0.074167\n# 11   contact_cellular    0.067707\n# 4             housing    0.044851\n# 21          month_oct    0.037620\n# 15          month_apr    0.034245\n# 17          month_jun    0.033480\n# 20          month_sep    0.030168\n# 12  contact_telephone    0.024734\n# 5                loan    0.022850\n# 27    job_blue-collar    0.020831\n# 16          month_may    0.019547\n# 13          month_feb    0.017789\n# 18          month_jul    0.014844\n# 22          month_nov    0.013827\n# 23          month_dec    0.013768\n# 19          month_aug    0.012835\n# 9               pdays    0.009650\n# 10           previous    0.009134\n\n\n\n#v4 con feat eng , xgb 25 iteraciones one-hot (CV): 0.9673 en competencia 0.9685 en competencia , por ahora mejor el anterior \n#falta que pruebe con mas de 1000 iteraciones para ver si mejora mas\n# xgb_model4 = xgb.XGBClassifier(\n#         n_estimators=377,\n#         learning_rate=0.0447,\n#         max_depth=9,\n#         subsample=0.7483,\n#         colsample_bytree=0.6296,\n#         colsample_bylevel=0.9085,\n#         min_child_weight=9,\n#         gamma=0.1792,\n#         reg_alpha=0.4494,\n#         reg_lambda=0.0954,\n#         random_state=42,\n#         n_jobs=-1,\n#         eval_metric='auc',\n#         use_label_encoder=False,\n#         verbosity=0\n# )\n#               feature  importance\n# 33    poutcome_success    0.226028\n# 12      Non_interested    0.155270\n# 7             duration    0.079444\n# 17         Insistencia    0.051111\n# 18    contact_cellular    0.047980\n# 4              housing    0.042457\n# 15    Financial_issues    0.040018\n# 24           month_jun    0.029941\n# 11  month_success_rate    0.024906\n# 21           month_mar    0.024538\n# 13               S_R_U    0.019711\n# 19   contact_telephone    0.017600\n# 26           month_aug    0.015405\n# 22           month_apr    0.015267\n# 28           month_oct    0.014416\n# 5                 loan    0.013715\n# 29           month_nov    0.012797\n# 36     job_blue-collar    0.011803\n# 20           month_feb    0.010032\n# 27           month_sep    0.008990\n\n# viendo si el Feat Eng tuvo efecto\n# NUEVAS FEATURES AGREGADAS:\n# - month_success_rate: Tasa de éxito histórica por mes (0-1)\n# - Non_interested: Clientes con bajo balance, duración corta y contacto desconocido\n# - S_R_U: Estudiantes, jubilados o desempleados jóvenes (<25) o mayores (>=65)\n# - TM: Educación terciaria y solteros\n# - Financial_issues: Tienen algún tipo de préstamo o problema crediticio\n# - Weekend: Contactados en fin de semana\n# - Insistencia: Casos de baja insistencia (nunca contactados, hace mucho tiempo, o sin contactos previos)\n\n#v5 lgb 1750 iteraciones Mejor score (CV): 0.9685 en competencia 0.96972\n# lgb_model5 = LGBMClassifier(\n#     random_state=42,\n#     n_jobs=-5,\n#     objective='binary',  \n#     boosting_type='gbdt',\n#     metric='binary_logloss',\n#     n_estimators=366,\n#     max_depth=-1,\n#     learning_rate=0.0702,\n#     num_leaves=148,\n#     subsample=0.9878,\n#     colsample_bytree=0.7205,\n#     min_child_samples=36,\n#     reg_alpha=0.3872,\n#     reg_lambda=0.9090\n# )\n\n#v6 no cambie parametros\n\n#v7 xgb 1750 iter Mejor score (CV): 0.9679  , en competencia 0.96914 en competencia\n\n# xgb_model7 = xgb.XGBClassifier(\n#         n_estimators=475,\n#         learning_rate=0.0718,\n#         max_depth=9,\n#         subsample=0.8006,\n#         colsample_bytree=0.8169,\n#         colsample_bylevel=0.7323,\n#         min_child_weight=7,\n#         gamma=0.4794,\n#         reg_alpha=0.6923,\n#         reg_lambda=0.9114,\n#         random_state=42,\n#         n_jobs=-1,\n#         eval_metric='auc',\n#         use_label_encoder=False,\n#         verbosity=2\n\n#v8 ensemble lgb 1750 iter Mejor score (CV): 0.9685 + xgb 1750 iter Mejor score (CV): 0.9679  , en competencia 0.96985\n\n# el puesto 1 al momento tiene 0.97785 , para continuar tengo varias opciones , catboost , ensemble pero haciendo staking ,\n# feat eng mas avanzado , creo que voy a dejar corriendo un catboost con 2500 iteraciones y hago staking de eso\n# dependiendo como resulte , continuaria por eng feat mas avanzado y de nuevo dejar corriendo xgb/lgbm/catboost con mas de 2000 iteraciones cada uno\n# y haria el staking y lo dejaria , porque prefiero seguir aprendiendo de mas competencias , obviamente volveria a revisar como termino\n# y leer las estrategias ganados y discusiones para aprender\n\n#v9 catboost tardo mucho y fallo , veo despues si lo hago , staking entre lgb5 y xgb7 , en competencia 0.96990\n\n\n#feat eng adicional\n# df['age_duration'] = df['age'] * df['duration']\n# df['balance_duration'] = df['balance'] * df['duration'] \n# df['campaign_previous'] = df['campaign'] * df['previous']\n# df['pdays_previous'] = df['pdays'] * df['previous']\n# df['balance_per_age'] = df['balance'] / (df['age'] + 1)\n# df['duration_per_campaign'] = df['duration'] / (df['campaign'] + 1)\n\n# === CORRELACIONES CON TARGET ===\n# age_duration: 0.490\n# balance_duration: 0.250\n# campaign_previous: 0.052\n# pdays_previous: 0.064\n# balance_per_age: 0.129\n# duration_per_campaign: 0.504\n\n#v10 0.96969 en competencia , bien porque no esta optimizado\n#se que deberia probar nuevas iteraciones para poder verificar si ayudan a aumentar el poder predictivo y tambien\n# comparar si las que tienen correlacion por debajo del 10% se quedan o se eliminan\n# pruebo el ultimo staking que hizo con esto y a la noche dejo probando nuevas iteraciones para decidir\n\n# el catboost no termina nunca , 2500 iteraciones de xgb o lgb , aprox 7/8 horas , 500 iteraciones catboost +6 horas y no termina , opto por dejarlo\n#v11 2500 iteraciones lgb cv score 0.9681 ,2500 iteracion xgb cv score 0.9676 , aca no mejoraron , pruebo ensemble para si es mejor en test\n#                                                                             en competencia 0.96964 PEOR QUE EL NO OPTIMIZADO\n#por lo viste el feat eng adicional , no fue util y parece haber metido ruido\n#dejo por aca el modelo y vuelvo para ver como fue la competencia ,cuales fueran las estrategias ganadoras\n\n\n\n# lgb_model11 = LGBMClassifier(\n#     random_state=42,\n#     n_jobs=-5,\n#     objective='binary',  \n#     boosting_type='gbdt',\n#     metric='binary_logloss',\n#     n_estimators=366,\n#     max_depth=-1,\n#     learning_rate=0.0702,\n#     num_leaves=148,\n#     subsample=0.9878,\n#     colsample_bytree=0.7205,\n#     min_child_samples=36,\n#     reg_alpha=0.3872,\n#     reg_lambda=0.9090\n# )\n\n# xgb_model11 = xgb.XGBClassifier(\n#         n_estimators=475,\n#         learning_rate=0.7180,\n#         max_depth=9,\n#         subsample=0.8006,\n#         colsample_bytree=0.8169,\n#         colsample_bylevel=0.7323,\n#         min_child_weight=7,\n#         gamma=0.4794,\n#         reg_alpha=0.6923,\n#         reg_lambda=0.9114,\n#         random_state=42,\n#         n_jobs=-1,\n#         eval_metric='auc',\n#         use_label_encoder=False,\n#         verbosity=2\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T23:58:18.563535Z","iopub.status.idle":"2025-08-13T23:58:18.563800Z","shell.execute_reply.started":"2025-08-13T23:58:18.563678Z","shell.execute_reply":"2025-08-13T23:58:18.563689Z"}},"outputs":[],"execution_count":null}]}